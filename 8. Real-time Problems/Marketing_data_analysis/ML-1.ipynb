{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "Typical office material supply company running their operations sees many challenges, one of the major ones being how to measure the effectiveness of sales and marketing operations. We have picked up an imaginary office material supply company “Office Corp.” for our analysis. They have tested a telemarketing campaign targeting existing domestic business customers with a random selection of products. For this exercise, a sample of 16,172 customers were targeted. The products being marketed are Desk, Executive Chair, Standard Chair, Monitor, Printer Computer, Insurance, Toner and Office Supplies.  \n",
    "\n",
    "Office Corp would like to leverage the knowledge gained from this survey (and associated dataset) for future campaigns. Office Corp has hired an analyst team to solve the following three problems using various analytical techniques.  \n",
    "\n",
    "- Profile the customers that responded to the campaign to understand the characteristics of customers who made purchases. \n",
    "\n",
    "- Develop models using the campaign results to target responsive, profitable customers for future campaigns. \n",
    "\n",
    "- Summarize and categorize the profitability of the various marketing segments which may be used to optimize future campaigns.\n",
    "\n",
    "---\n",
    "\n",
    "## Scientific questions/investigation\n",
    "\n",
    "Given marketing dataset, there are three key problems to solve.  \n",
    "\n",
    "- Given campaign period data, looking at customer profile, we aim to predict whether customer will Buy or Not Buy. We intent to frame this as a Classification problem. \n",
    "\n",
    "- Among the customers who are predicted as they will buy, we aim to estimate what will be size of purchase. We intent to frame this as a Regression problem. \n",
    "\n",
    "- For those customers who are likely to purchase and in general other customers using their historical product purchase data, we aim to predict top 3 products that are likely to be purchased. Also try to predict whether there are any product bundles Office Corp may sell more, etc. We intend to frame this as a Clustering problem.  \n",
    "\n",
    "In the process of analysis, we intent to carry out,  \n",
    "\n",
    "- data missing and imputation treatments,  \n",
    "\n",
    "- data sufficiency and randomized splitting for test-train sets,  \n",
    "\n",
    "- test amount of data necessary for optimal predictions & accuracy, etc.  \n",
    "\n",
    "This last topic of determining optimal amount of data is called the ‘sample complexity study’ and it is extremely important for such real-life marketing campaign problems because collecting too much data unnecessarily may cause the company cost overrun. Data scientists should be able to advise the business department on how much data to collect to achieve a decent model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']=125\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load (cleaned and formatted) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"AddedFeatures_campaign_sale.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['Customer_engagement_length',\n",
    "       'Language_group', 'Repurchase Method', 'Last Transaction Channel',\n",
    "       'Number of Employees', 'Service Level', 'Do No Disturb',\n",
    "       'Email Available', 'Desk', 'Executive Chair', 'Standard Chair',\n",
    "       'Monitor', 'Printer', 'Computer', 'Insurance', 'Toner',\n",
    "       'Office Supplies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.get_dummies(df,columns=cat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Logistic Regression\",\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\", \"Bagging\",\n",
    "         \"Naive Bayes\", \"QDA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of classifier (Scikit-learn estimator objects with hyperparamemetr settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LogisticRegression(C=0.1,n_jobs=-1),\n",
    "    KNeighborsClassifier(10,n_jobs=-1),\n",
    "    SVC(kernel=\"linear\", C=0.1),\n",
    "    SVC(gamma='scale', C=1),\n",
    "    DecisionTreeClassifier(max_depth=10,min_samples_leaf=10),\n",
    "    RandomForestClassifier(max_depth=3, n_estimators=50, \n",
    "                           max_features=5,min_samples_leaf=10,n_jobs=-1),\n",
    "    MLPClassifier(hidden_layer_sizes=(100,100),alpha=0.2, \n",
    "                  max_iter=200,learning_rate_init=0.01,learning_rate='adaptive',\n",
    "                 early_stopping=True,validation_fraction=0.2),\n",
    "    AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=3),\n",
    "                       n_estimators=50,learning_rate=0.1),\n",
    "    BaggingClassifier(estimator=DecisionTreeClassifier(max_depth=3),\n",
    "                       n_estimators=50, max_features=5,n_jobs=-1),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(reg_param=0.1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = d.drop(['Campaign Period Sales','Buy'],axis=1)\n",
    "y = d['Buy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FRAC = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=TEST_FRAC, \n",
    "                                                    random_state=7406)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running through the classifiers once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "    t1 = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    delta_t = round((t2-t1)*1000,3)\n",
    "    score = round(clf.score(X_test, y_test),3)\n",
    "    print(f\"Fitting with {name} took {delta_t} ms.\\n Score: {score}\")\n",
    "    print(\"-\"*75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to run through classifiers repeatedly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifiers(clf_lst,names=None,num_runs=10, verbose=0):\n",
    "    \"\"\"\n",
    "    Runs the list of classifiers for a fixed number of times\n",
    "    \"\"\"\n",
    "    if names is None:\n",
    "        names = [str(type(c)).split('.')[-1][:-2] for c in clf_lst]\n",
    "    scores = dict.fromkeys(names,[])\n",
    "    f1_scores = dict.fromkeys(names,[])\n",
    "    runtimes = dict.fromkeys(names,[])\n",
    "    for name, clf in zip(names, clf_lst):\n",
    "        sc,f1,rt= [],[],[]\n",
    "        for i in range(num_runs):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_FRAC,)\n",
    "            X_train = StandardScaler().fit_transform(X_train)\n",
    "            X_test = StandardScaler().fit_transform(X_test)\n",
    "            t1 = time.time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            t2 = time.time()\n",
    "            delta_t = round((t2-t1)*1000,3)\n",
    "            score = round(clf.score(X_test, y_test),3)\n",
    "            f1score = f1_score(y_test,clf.predict(X_test))\n",
    "            sc.append(score)\n",
    "            f1.append(f1score)\n",
    "            rt.append(delta_t)\n",
    "        sc = np.array(sc)\n",
    "        f1 = np.array(f1)\n",
    "        rt = np.array(rt)\n",
    "        scores[name] = sc\n",
    "        f1_scores[name] = f1\n",
    "        runtimes[name] = rt\n",
    "        if verbose:\n",
    "            print(f\"Finished {num_runs} runs for {name} algorithm\")\n",
    "            print(\"-\"*75)\n",
    "    # Convert to DataFrame\n",
    "    df_scores = pd.DataFrame(scores)\n",
    "    df_f1scores = pd.DataFrame(f1_scores)\n",
    "    df_runtimes = pd.DataFrame(runtimes)\n",
    "    \n",
    "    return df_scores, df_f1scores,df_runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run through clasifiers and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1,d2,d3 = run_classifiers(clf_lst=classifiers,\n",
    "                           names=names,\n",
    "                           num_runs=25,\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bars(d,\n",
    "              t1=\"Mean accuracy score of algorithms\",\n",
    "              t2=\"Std.dev of the accuracy scores of algorithms\"):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    fig,ax=plt.subplots(1,2,figsize=(14,5))\n",
    "    ax[0].barh(y=list(d.columns),width=d.describe().T['mean'],height=0.6,color='goldenrod')\n",
    "    ax[0].set_title(t1)\n",
    "    ax[1].barh(y=list(d.columns),width=d.describe().T['std'],height=0.6,color='dodgerblue')\n",
    "    ax[1].set_title(t2)\n",
    "    ax[0].spines['top'].set_visible(False)\n",
    "    ax[0].spines['right'].set_visible(False)\n",
    "    ax[0].spines['left'].set_visible(False)\n",
    "    ax[0].spines['bottom'].set_color('#DDDDDD')\n",
    "    ax[1].spines['top'].set_visible(False)\n",
    "    ax[1].spines['right'].set_visible(False)\n",
    "    ax[1].spines['left'].set_visible(False)\n",
    "    ax[1].spines['bottom'].set_color('#DDDDDD')\n",
    "    plt.tight_layout(pad=1.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams['xtick.labelsize']=13\n",
    "mpl.rcParams['ytick.labelsize']=13\n",
    "mpl.rcParams['figure.dpi']=125\n",
    "mpl.rcParams['axes.titlesize']=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bars(d1,\n",
    "          t1=\"Mean accuracy score of algorithms\",\n",
    "          t2=\"Std.dev of the accuracy scores of algorithms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bars(d2,\n",
    "          t1=\"Mean F1-score of algorithms\",\n",
    "          t2=\"Std.dev of the F1-scores of algorithms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bars(d3,\n",
    "          t1=\"Mean training time of algorithms\",\n",
    "          t2=\"Std.dev of the training time of algorithms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search of `AdaBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "abc = AdaBoostClassifier(estimator=DecisionTreeClassifier(), algorithm='SAMME')\n",
    "parameters = {'estimator__max_depth':[i for i in range(2,11,2)],\n",
    "              'estimator__min_samples_leaf':[5,10],\n",
    "              'n_estimators':[10,50,250,1000],\n",
    "              'learning_rate':[0.01,0.1]}\n",
    "clf = GridSearchCV(abc, parameters,verbose=3,scoring='f1',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_grid=pd.DataFrame(clf.cv_results_['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_grid['F1-score']=clf.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2,figsize=(6,4))\n",
    "ax= ax.ravel()\n",
    "for i,c in enumerate(boost_grid.columns[:-1]):\n",
    "    ax[i].scatter(boost_grid[c],boost_grid['F1-score'],\n",
    "                 c='blue',edgecolor='k',alpha=0.7,s=150,\n",
    "                 )\n",
    "    ax[i].set_title(f\"F1-score vs. {c}\",fontsize=12)\n",
    "    ax[i].set_ylim(0.5,0.8)\n",
    "    ax[i].spines['top'].set_visible(False)\n",
    "    ax[i].spines['right'].set_visible(False)\n",
    "    ax[i].grid(True)\n",
    "plt.tight_layout(pad=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of regressors (Scikit-learn estimator objects with hyperparamemetr settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_names = [\"Linear regression\",\"L1 (LASSO) regression\",\"Ridge regression\",\n",
    "            \"Support vector regression\",\"Decision tree regression\",\n",
    "            \"Random forest regression\",\"Neural network regression\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [LinearRegression(n_jobs=-1),\n",
    "              Lasso(alpha=0.1),\n",
    "              Ridge(alpha=0.1),\n",
    "              SVR(kernel='poly',degree=3),\n",
    "              DecisionTreeRegressor(max_depth=10,min_samples_leaf=10),\n",
    "              RandomForestRegressor(max_depth=3, n_estimators=50, \n",
    "                           max_features=5,min_samples_leaf=10,n_jobs=-1),\n",
    "              MLPRegressor(hidden_layer_sizes=(100,100),alpha=0.2, \n",
    "                  max_iter=200,learning_rate_init=0.01,learning_rate='adaptive',\n",
    "                 early_stopping=True,validation_fraction=0.2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression data and test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_reg= d[d['Campaign Period Sales']>0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = d_reg.drop(['Campaign Period Sales','Buy'],axis=1)\n",
    "y = d_reg['Campaign Period Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to run through classifiers repeatedly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regressors(reg_lst,names=None,num_runs=10, verbose=0):\n",
    "    \"\"\"\n",
    "    Runs the list of regressors for a fixed number of times\n",
    "    \"\"\"\n",
    "    if names is None:\n",
    "        names = [str(type(c)).split('.')[-1][:-2] for c in reg_lst]\n",
    "    scores = dict.fromkeys(names,[])\n",
    "    runtimes = dict.fromkeys(names,[])\n",
    "    for name, reg in zip(names, reg_lst):\n",
    "        sc,rt= [],[]\n",
    "        for i in range(num_runs):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_FRAC,)\n",
    "            X_train = StandardScaler().fit_transform(X_train)\n",
    "            X_test = StandardScaler().fit_transform(X_test)\n",
    "            t1 = time.time()\n",
    "            reg.fit(X_train, y_train)\n",
    "            t2 = time.time()\n",
    "            delta_t = round((t2-t1)*1000,3)\n",
    "            rmse = round(np.sqrt(np.mean((reg.predict(X_test)-y_test)**2).mean()),3)\n",
    "            sc.append(rmse)\n",
    "            rt.append(delta_t)\n",
    "        sc = np.array(sc)\n",
    "        rt = np.array(rt)\n",
    "        scores[name] = sc\n",
    "        runtimes[name] = rt\n",
    "        if verbose:\n",
    "            print(f\"Finished {num_runs} runs for {name} algorithm\")\n",
    "            print(\"-\"*75)\n",
    "    # Convert to DataFrame\n",
    "    df_scores = pd.DataFrame(scores)\n",
    "    df_runtimes = pd.DataFrame(runtimes)\n",
    "    \n",
    "    return df_scores,df_runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run through regressors and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_reg, d2_reg = run_regressors(reg_lst=regressors,names=reg_names,num_runs=5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_reg1 = d1_reg.drop(['Linear regression'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_reg1['Neural network regression'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bars(d1_reg1,\n",
    "          t1=\"RMSE score of algorithms\",\n",
    "          t2=\"Std.dev of the RMSE scores of algorithms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bars(d2_reg,\n",
    "          t1=\"Mean training time of algorithms\",\n",
    "          t2=\"Std.dev of the training time of algorithms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.hist(y,bins=100,edgecolor='k')\n",
    "plt.xlim(0,2000)\n",
    "plt.vlines(x=398,ymin=0,ymax=600,color='k',linestyle='--',linewidth=3)\n",
    "plt.vlines(x=d1_reg1['Neural network regression'].mean(),\n",
    "           ymin=0,ymax=600,color='orange',linestyle='--',linewidth=3)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression prediction and ground truth match plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_FRAC,)\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)\n",
    "nn_reg = MLPRegressor(hidden_layer_sizes=(100,100),alpha=0.2, \n",
    "                  max_iter=200,learning_rate_init=0.01,learning_rate='adaptive',\n",
    "                 early_stopping=True,validation_fraction=0.2)\n",
    "nn_reg.fit(X_train,y_train)\n",
    "preds = nn_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.scatter(x=y_test,y=preds,edgecolor='k',alpha=0.7,c='blue')\n",
    "plt.plot(y_test,y_test,c='red')\n",
    "plt.xlim(0,5000)\n",
    "plt.ylim(0,5000)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"True campaign sales\",fontsize=15)\n",
    "plt.ylabel(\"Predicted campaign sales\",fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_FRAC,)\n",
    "xlim = y_test.max()\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(2,3,figsize=(15,10))\n",
    "ax= ax.ravel()\n",
    "for i in range(6):\n",
    "    reg = regressors[1:][i]\n",
    "    reg.fit(X_train,y_train)\n",
    "    preds = reg.predict(X_test)\n",
    "    ax[i].scatter(x=y_test,y=preds,edgecolor='k',alpha=0.7,c='blue')\n",
    "    ax[i].plot(y_test,y_test,c='red')\n",
    "    ax[i].set_xlim(0,xlim*1.1)\n",
    "    ax[i].set_ylim(0,xlim*1.1)\n",
    "    ax[i].spines['top'].set_visible(False)\n",
    "    ax[i].spines['right'].set_visible(False)\n",
    "    ax[i].grid(True)\n",
    "    ax[i].set_xlabel(\"True campaign sales\",fontsize=15)\n",
    "    ax[i].set_ylabel(\"Predicted campaign sales\",fontsize=15)\n",
    "    ax[i].set_title(reg_names[1:][i])\n",
    "plt.tight_layout(pad=1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN model tuning for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_neurons = [i*10 for i in range(1,11)]\n",
    "alpha = [0.01,0.1,0.2,0.5]\n",
    "learning_rate = [0.01,0.05,0.1]\n",
    "activation = ['relu','tanh','logistic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_grid = {'neurons':[],'alpha':[],'learning_rate':[],'activation':[],'RMSE':[],'training-time':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = d_reg.drop(['Campaign Period Sales','Buy'],axis=1)\n",
    "y = d_reg['Campaign Period Sales']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=TEST_FRAC, \n",
    "                                                    random_state=7406)\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for n in tqdm(no_neurons):\n",
    "    for a in tqdm(alpha):\n",
    "        for l in learning_rate:\n",
    "            for act in activation:\n",
    "                reg = MLPRegressor(hidden_layer_sizes=(n,n),alpha=a,activation=act, \n",
    "                  max_iter=200,learning_rate_init=l,learning_rate='adaptive',\n",
    "                 early_stopping=True,validation_fraction=0.2)\n",
    "                t1 = time.time()\n",
    "                reg.fit(X_train, y_train)\n",
    "                t2 = time.time()\n",
    "                delta_t = round((t2-t1)*1000,3)\n",
    "                rmse = round(np.sqrt(np.mean((reg.predict(X_test)-y_test)**2).mean()),3)\n",
    "                nn_grid['neurons'].append(n)\n",
    "                nn_grid['alpha'].append(a)\n",
    "                nn_grid['learning_rate'].append(l)\n",
    "                nn_grid['activation'].append(act)\n",
    "                nn_grid['RMSE'].append(rmse)\n",
    "                nn_grid['training-time'].append(delta_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_grid=pd.DataFrame(nn_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=[i for i in range(len(nn_grid))],y=nn_grid['RMSE'])\n",
    "plt.ylim(0,600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,2,figsize=(12,10))\n",
    "ax= ax.ravel()\n",
    "for i,c in enumerate(nn_grid.columns[:4]):\n",
    "    ax[i].scatter(nn_grid[c],nn_grid['RMSE'],edgecolor='k',alpha=0.7,c='blue')\n",
    "    ax[i].set_title(f\"RMSE vs. {c}\")\n",
    "    ax[i].grid(True)\n",
    "    ax[i].spines['top'].set_visible(False)\n",
    "    ax[i].spines['right'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_complexity = dict.fromkeys(names,[])\n",
    "frac = [0.1*i for i in range(1,11)]\n",
    "for name,clf in list(zip(names,classifiers)):\n",
    "    scores = []\n",
    "    for f in frac:\n",
    "        d_frac = d.sample(frac=f)\n",
    "        X = d_frac.drop(['Campaign Period Sales','Buy'],axis=1)\n",
    "        y = d_frac['Buy']\n",
    "        TEST_FRAC = 0.2\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=TEST_FRAC,random_state=7406)\n",
    "        X_train = StandardScaler().fit_transform(X_train)\n",
    "        X_test = StandardScaler().fit_transform(X_test)\n",
    "        t1 = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        t2 = time.time()\n",
    "        delta_t = round((t2-t1)*1000,3)\n",
    "        f1score = f1_score(y_test,clf.predict(X_test))\n",
    "        scores.append(f1score)\n",
    "    sample_complexity[name] = np.array(scores)\n",
    "        #print(sample_complexity[name])\n",
    "    print(f\"Done for {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_complexity=pd.DataFrame(sample_complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(4,3,figsize=(16,16),sharey=True)\n",
    "ax = ax.ravel()\n",
    "for i,c in enumerate(sample_complexity.columns):\n",
    "    ax[i].plot([int(j) for j in range(1,11)],sample_complexity[c],marker='o',color='blue')\n",
    "    ax[i].set_xticks([int(j) for j in range(1,11,2)])\n",
    "    ax[i].set_xticklabels([str(10*j)+'%' for j in range(1,11,2)])\n",
    "    ax[i].set_title(f\"{c}\",fontsize=14)\n",
    "    ax[i].grid(True)\n",
    "    ax[i].spines['top'].set_visible(False)\n",
    "    ax[i].spines['right'].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da5401",
   "language": "python",
   "name": "da5401"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
