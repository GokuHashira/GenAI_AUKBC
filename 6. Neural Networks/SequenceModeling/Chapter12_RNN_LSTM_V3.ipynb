{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:18:44.092034Z",
     "start_time": "2025-01-21T03:18:40.774989Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 22:24:06.968587: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-09 22:24:06.983949: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746809647.002825  158724 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746809647.008025  158724 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-09 22:24:07.026628: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Importing dependencies\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from tensorflow.keras.models import Sequential\n",
    "from numpy import array, argmax, random, take\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import RNN, SimpleRNN, LSTM,  Embedding, RepeatVector\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "#For plotting the matplotlib graphs in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:19:05.392654Z",
     "start_time": "2025-01-21T03:19:05.389760Z"
    }
   },
   "outputs": [],
   "source": [
    "Data_path=\"./Datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:19:13.830925Z",
     "start_time": "2025-01-21T03:19:13.821783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data (5351, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "column_names = ['word1', 'word2', 'word3']\n",
    "\n",
    "input_3gram = pd.read_csv(Data_path+ \"/3Gram_love_data.txt\", delimiter='\\t', names=column_names) #Importing csv file with column names\n",
    "print(\"shape of data\", input_3gram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:19:16.392744Z",
     "start_time": "2025-01-21T03:19:16.385907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few sample records from data \n",
      "       word1 word2       word3\n",
      "1813   love  that        kind\n",
      "6      hate    to  disappoint\n",
      "91     hate    to         use\n",
      "2646   love   the         way\n",
      "5080  loved    to        play\n",
      "4674   love    it        when\n",
      "4009   love    it        when\n",
      "4640   love    it        when\n",
      "1255   love   for         you\n",
      "2359   love   him         and\n"
     ]
    }
   ],
   "source": [
    "print(\"Few sample records from data \\n\", input_3gram.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:19:19.028244Z",
     "start_time": "2025-01-21T03:19:19.021500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequency of word1 values \n",
      " word1\n",
      "love      4327\n",
      "loved      416\n",
      "hate       400\n",
      "hated       80\n",
      "loves       72\n",
      "lovely      24\n",
      "loving      24\n",
      "hates        8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frequency of word2 values \n",
      " word2\n",
      "to         1866\n",
      "it         1361\n",
      "the         548\n",
      "with        240\n",
      "him         144\n",
      "you         144\n",
      "of          136\n",
      "her         104\n",
      "for          96\n",
      "and          88\n",
      "what         56\n",
      "is           48\n",
      "each         40\n",
      "in           40\n",
      "ones         32\n",
      "me           32\n",
      "nothing      32\n",
      "them         32\n",
      "as           24\n",
      "every        24\n",
      "more         16\n",
      "going        16\n",
      "that         16\n",
      "being        16\n",
      "affair       16\n",
      "my           16\n",
      "about         8\n",
      "your          8\n",
      "on            8\n",
      "letter        8\n",
      "most          8\n",
      "thy           8\n",
      "view          8\n",
      "song          8\n",
      "makes         8\n",
      "got           8\n",
      "this          8\n",
      "at            8\n",
      "a             8\n",
      "one           8\n",
      "hearing       8\n",
      "story         8\n",
      "all           8\n",
      "lost          8\n",
      "man           8\n",
      "when          8\n",
      "husband       8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFrequency of word1 values \\n\", input_3gram[\"word1\"].value_counts())\n",
    "print(\"\\nFrequency of word2 values \\n\", input_3gram[\"word2\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:19:21.897832Z",
     "start_time": "2025-01-21T03:19:21.889900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique words overall: 139\n",
      "unique words list: ['a' 'able' 'about' 'admit' 'affair' 'affection' 'all' 'and' 'another'\n",
      " 'answer' 'as' 'at' 'be' 'because' 'being' 'better' 'between' 'bother'\n",
      " 'break' 'care' 'cared' 'come' 'concern' 'country' 'cut' 'disappoint' 'do'\n",
      " 'each' 'every' 'fact' 'feel' 'feeling' 'find' 'first' 'for' 'from' 'get'\n",
      " 'go' 'god' 'going' 'got' 'hate' 'hated' 'hates' 'have' 'he' 'hear'\n",
      " 'hearing' 'her' 'here' 'him' 'his' 'husband' 'i' 'idea' 'if' 'in'\n",
      " 'interrupt' 'is' 'it' 'kind' 'know' 'leave' 'letter' 'life' 'like'\n",
      " 'listen' 'look' 'lost' 'lot' 'love' 'loved' 'lovely' 'loves' 'loving'\n",
      " 'make' 'makes' 'man' 'marriage' 'me' 'minute' 'more' 'most' 'much'\n",
      " 'music' 'my' 'nature' 'neighbor' 'not' 'nothing' 'of' 'on' 'one' 'ones'\n",
      " 'or' 'other' 'over' 'play' 'respect' 'say' 'see' 'sit' 'smell' 'so'\n",
      " 'someone' 'song' 'sound' 'story' 'stronger' 'support' 'take' 'talk'\n",
      " 'tell' 'than' 'that' 'the' 'them' 'they' 'think' 'this' 'thought' 'thy'\n",
      " 'to' 'too' 'united' 'use' 'very' 'view' 'watch' 'way' 'we' 'what' 'when'\n",
      " 'wife' 'will' 'with' 'work' 'you' 'your']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Finding our words to create dictionary\n",
    "Here we find unique values in each column and save each of those values .\n",
    "Later which we will take the unique value for the entire appened columns\n",
    "This will be our vocabulary list,which are the unique words in our data file\n",
    "\"\"\"\n",
    "unique_words = []\n",
    "for i in list(input_3gram.columns.values):\n",
    "    for j in pd.unique(input_3gram[i]):\n",
    "        unique_words.append(j)\n",
    "unique_words = np.unique(unique_words)\n",
    "\n",
    "\n",
    "print('Count of unique words overall:', len(unique_words))\n",
    "print('unique words list:', unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:19:22.920391Z",
     "start_time": "2025-01-21T03:19:22.914261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_indices dictionary \n",
      " {'a': 0, 'able': 1, 'about': 2, 'admit': 3, 'affair': 4, 'affection': 5, 'all': 6, 'and': 7, 'another': 8, 'answer': 9, 'as': 10, 'at': 11, 'be': 12, 'because': 13, 'being': 14, 'better': 15, 'between': 16, 'bother': 17, 'break': 18, 'care': 19, 'cared': 20, 'come': 21, 'concern': 22, 'country': 23, 'cut': 24, 'disappoint': 25, 'do': 26, 'each': 27, 'every': 28, 'fact': 29, 'feel': 30, 'feeling': 31, 'find': 32, 'first': 33, 'for': 34, 'from': 35, 'get': 36, 'go': 37, 'god': 38, 'going': 39, 'got': 40, 'hate': 41, 'hated': 42, 'hates': 43, 'have': 44, 'he': 45, 'hear': 46, 'hearing': 47, 'her': 48, 'here': 49, 'him': 50, 'his': 51, 'husband': 52, 'i': 53, 'idea': 54, 'if': 55, 'in': 56, 'interrupt': 57, 'is': 58, 'it': 59, 'kind': 60, 'know': 61, 'leave': 62, 'letter': 63, 'life': 64, 'like': 65, 'listen': 66, 'look': 67, 'lost': 68, 'lot': 69, 'love': 70, 'loved': 71, 'lovely': 72, 'loves': 73, 'loving': 74, 'make': 75, 'makes': 76, 'man': 77, 'marriage': 78, 'me': 79, 'minute': 80, 'more': 81, 'most': 82, 'much': 83, 'music': 84, 'my': 85, 'nature': 86, 'neighbor': 87, 'not': 88, 'nothing': 89, 'of': 90, 'on': 91, 'one': 92, 'ones': 93, 'or': 94, 'other': 95, 'over': 96, 'play': 97, 'respect': 98, 'say': 99, 'see': 100, 'sit': 101, 'smell': 102, 'so': 103, 'someone': 104, 'song': 105, 'sound': 106, 'story': 107, 'stronger': 108, 'support': 109, 'take': 110, 'talk': 111, 'tell': 112, 'than': 113, 'that': 114, 'the': 115, 'them': 116, 'they': 117, 'think': 118, 'this': 119, 'thought': 120, 'thy': 121, 'to': 122, 'too': 123, 'united': 124, 'use': 125, 'very': 126, 'view': 127, 'watch': 128, 'way': 129, 'we': 130, 'what': 131, 'when': 132, 'wife': 133, 'will': 134, 'with': 135, 'work': 136, 'you': 137, 'your': 138}\n",
      "word_indices.keys \n",
      " dict_keys(['a', 'able', 'about', 'admit', 'affair', 'affection', 'all', 'and', 'another', 'answer', 'as', 'at', 'be', 'because', 'being', 'better', 'between', 'bother', 'break', 'care', 'cared', 'come', 'concern', 'country', 'cut', 'disappoint', 'do', 'each', 'every', 'fact', 'feel', 'feeling', 'find', 'first', 'for', 'from', 'get', 'go', 'god', 'going', 'got', 'hate', 'hated', 'hates', 'have', 'he', 'hear', 'hearing', 'her', 'here', 'him', 'his', 'husband', 'i', 'idea', 'if', 'in', 'interrupt', 'is', 'it', 'kind', 'know', 'leave', 'letter', 'life', 'like', 'listen', 'look', 'lost', 'lot', 'love', 'loved', 'lovely', 'loves', 'loving', 'make', 'makes', 'man', 'marriage', 'me', 'minute', 'more', 'most', 'much', 'music', 'my', 'nature', 'neighbor', 'not', 'nothing', 'of', 'on', 'one', 'ones', 'or', 'other', 'over', 'play', 'respect', 'say', 'see', 'sit', 'smell', 'so', 'someone', 'song', 'sound', 'story', 'stronger', 'support', 'take', 'talk', 'tell', 'than', 'that', 'the', 'them', 'they', 'think', 'this', 'thought', 'thy', 'to', 'too', 'united', 'use', 'very', 'view', 'watch', 'way', 'we', 'what', 'when', 'wife', 'will', 'with', 'work', 'you', 'your'])\n",
      "word_indices.values \n",
      " dict_values([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138])\n",
      "\n",
      " ########################################\n",
      "\n",
      "indices_words dictionary \n",
      " {0: 'a', 1: 'able', 2: 'about', 3: 'admit', 4: 'affair', 5: 'affection', 6: 'all', 7: 'and', 8: 'another', 9: 'answer', 10: 'as', 11: 'at', 12: 'be', 13: 'because', 14: 'being', 15: 'better', 16: 'between', 17: 'bother', 18: 'break', 19: 'care', 20: 'cared', 21: 'come', 22: 'concern', 23: 'country', 24: 'cut', 25: 'disappoint', 26: 'do', 27: 'each', 28: 'every', 29: 'fact', 30: 'feel', 31: 'feeling', 32: 'find', 33: 'first', 34: 'for', 35: 'from', 36: 'get', 37: 'go', 38: 'god', 39: 'going', 40: 'got', 41: 'hate', 42: 'hated', 43: 'hates', 44: 'have', 45: 'he', 46: 'hear', 47: 'hearing', 48: 'her', 49: 'here', 50: 'him', 51: 'his', 52: 'husband', 53: 'i', 54: 'idea', 55: 'if', 56: 'in', 57: 'interrupt', 58: 'is', 59: 'it', 60: 'kind', 61: 'know', 62: 'leave', 63: 'letter', 64: 'life', 65: 'like', 66: 'listen', 67: 'look', 68: 'lost', 69: 'lot', 70: 'love', 71: 'loved', 72: 'lovely', 73: 'loves', 74: 'loving', 75: 'make', 76: 'makes', 77: 'man', 78: 'marriage', 79: 'me', 80: 'minute', 81: 'more', 82: 'most', 83: 'much', 84: 'music', 85: 'my', 86: 'nature', 87: 'neighbor', 88: 'not', 89: 'nothing', 90: 'of', 91: 'on', 92: 'one', 93: 'ones', 94: 'or', 95: 'other', 96: 'over', 97: 'play', 98: 'respect', 99: 'say', 100: 'see', 101: 'sit', 102: 'smell', 103: 'so', 104: 'someone', 105: 'song', 106: 'sound', 107: 'story', 108: 'stronger', 109: 'support', 110: 'take', 111: 'talk', 112: 'tell', 113: 'than', 114: 'that', 115: 'the', 116: 'them', 117: 'they', 118: 'think', 119: 'this', 120: 'thought', 121: 'thy', 122: 'to', 123: 'too', 124: 'united', 125: 'use', 126: 'very', 127: 'view', 128: 'watch', 129: 'way', 130: 'we', 131: 'what', 132: 'when', 133: 'wife', 134: 'will', 135: 'with', 136: 'work', 137: 'you', 138: 'your'}\n",
      "indices_words keys \n",
      " dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138])\n",
      "indices_words values \n",
      " dict_values(['a', 'able', 'about', 'admit', 'affair', 'affection', 'all', 'and', 'another', 'answer', 'as', 'at', 'be', 'because', 'being', 'better', 'between', 'bother', 'break', 'care', 'cared', 'come', 'concern', 'country', 'cut', 'disappoint', 'do', 'each', 'every', 'fact', 'feel', 'feeling', 'find', 'first', 'for', 'from', 'get', 'go', 'god', 'going', 'got', 'hate', 'hated', 'hates', 'have', 'he', 'hear', 'hearing', 'her', 'here', 'him', 'his', 'husband', 'i', 'idea', 'if', 'in', 'interrupt', 'is', 'it', 'kind', 'know', 'leave', 'letter', 'life', 'like', 'listen', 'look', 'lost', 'lot', 'love', 'loved', 'lovely', 'loves', 'loving', 'make', 'makes', 'man', 'marriage', 'me', 'minute', 'more', 'most', 'much', 'music', 'my', 'nature', 'neighbor', 'not', 'nothing', 'of', 'on', 'one', 'ones', 'or', 'other', 'over', 'play', 'respect', 'say', 'see', 'sit', 'smell', 'so', 'someone', 'song', 'sound', 'story', 'stronger', 'support', 'take', 'talk', 'tell', 'than', 'that', 'the', 'them', 'they', 'think', 'this', 'thought', 'thy', 'to', 'too', 'united', 'use', 'very', 'view', 'watch', 'way', 'we', 'what', 'when', 'wife', 'will', 'with', 'work', 'you', 'your'])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "creating our word:indice pair dictionary and inverse\n",
    "Here will be creating two dictonary values\n",
    "word_indices : This contains each words mapped to an unique digit \n",
    "indices_words : This contains each digits mapped to a word in the same sequence as word_indices \n",
    "\"\"\"\n",
    "word_indices = dict((w, i) for i, w in enumerate(unique_words))\n",
    "indices_words = dict((i, w) for i, w in enumerate(unique_words))\n",
    "\n",
    "print(\"word_indices dictionary \\n\",word_indices)\n",
    "print(\"word_indices.keys \\n\", word_indices.keys())\n",
    "print(\"word_indices.values \\n\", word_indices.values())\n",
    "print(\"\\n ########################################\\n\")\n",
    "print(\"indices_words dictionary \\n\", indices_words)\n",
    "print(\"indices_words keys \\n\",indices_words.keys())\n",
    "print(\"indices_words values \\n\",indices_words.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:19:24.039521Z",
     "start_time": "2025-01-21T03:19:24.033384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word1_onehot shape is  (5351, 139)\n"
     ]
    }
   ],
   "source": [
    "### Onehot encoding of word1\n",
    "word1 = input_3gram['word1'].map(word_indices)\n",
    "word1_onehot = keras.utils.to_categorical(np.array(word1), num_classes=len(word_indices))\n",
    "print(\"word1_onehot shape is \",word1_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:19:26.218252Z",
     "start_time": "2025-01-21T03:19:26.210722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word in row 0 is -->hate\n",
      "The one hot encoded version of the word in row 0 is \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "The word in row 500 is --> love\n",
      "The one hot encoded version of the word in row 500 is \n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Lets take example of two different words\n",
    "print(\"The word in row 0 is -->\"+input_3gram['word1'][0])\n",
    "print(\"The one hot encoded version of the word in row 0 is \\n\",word1_onehot[0])\n",
    "\n",
    "print(\"\\nThe word in row 500 is --> \"+input_3gram['word1'][500])\n",
    "print(\"The one hot encoded version of the word in row 500 is \\n\",word1_onehot[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:19:27.247775Z",
     "start_time": "2025-01-21T03:19:27.238055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2_onehot shape is  (5351, 139)\n",
      "word3_onehot shape is  (5351, 139)\n"
     ]
    }
   ],
   "source": [
    "##one hot encoding for word2 and word3 \n",
    "word2 = input_3gram['word2'].map(word_indices)\n",
    "word2_onehot = keras.utils.to_categorical(np.array(word2), num_classes=len(word_indices))\n",
    "print(\"word2_onehot shape is \",word2_onehot.shape)\n",
    "\n",
    "word3 = input_3gram['word3'].map(word_indices)\n",
    "word3_onehot = keras.utils.to_categorical(np.array(word3), num_classes=len(word_indices))\n",
    "print(\"word3_onehot shape is \",word3_onehot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:19:39.961426Z",
     "start_time": "2025-01-21T03:19:38.242289Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudarsun/venv/da5401/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1746809669.971515  158724 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4177 MB memory:  -> device: 0, name: NVIDIA RTX A1000 6GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">139</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,529</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m139\u001b[0m)            │         \u001b[38;5;34m1,529\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,929</span> (11.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,929\u001b[0m (11.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,929</span> (11.44 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,929\u001b[0m (11.44 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ANN_model1 = Sequential()\n",
    "ANN_model1.add(Dense(10, input_dim=word1_onehot.shape[1], activation='sigmoid'))\n",
    "ANN_model1.add(Dense(word2_onehot.shape[1] ,activation='softmax'))\n",
    "ANN_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:19:46.581027Z",
     "start_time": "2025-01-21T03:19:41.202198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1746809674.322319  159811 service.cc:148] XLA service 0x74af9c017800 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1746809674.322346  159811 service.cc:156]   StreamExecutor device (0): NVIDIA RTX A1000 6GB Laptop GPU, Compute Capability 8.6\n",
      "2025-05-09 22:24:34.336780: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1746809674.402877  159811 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 70/108\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.0000e+00 - loss: 0.6562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1746809675.432927  159811 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.6300\n",
      "Epoch 2/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.0196 - loss: 0.3733    \n",
      "Epoch 3/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.3522 - loss: 0.2154\n",
      "Epoch 4/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.3438 - loss: 0.1339\n",
      "Epoch 5/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - accuracy: 0.3391 - loss: 0.0924\n",
      "Epoch 6/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.3450 - loss: 0.0696\n",
      "Epoch 7/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.3422 - loss: 0.0559\n",
      "Epoch 8/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.3411 - loss: 0.0475\n",
      "Epoch 9/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.3444 - loss: 0.0417\n",
      "Epoch 10/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.3418 - loss: 0.0379\n",
      "Epoch 11/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.3497 - loss: 0.0349\n",
      "Epoch 12/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.3554 - loss: 0.0327\n",
      "Epoch 13/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.3457 - loss: 0.0310\n",
      "Epoch 14/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.3559 - loss: 0.0296\n",
      "Epoch 15/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.3569 - loss: 0.0284\n",
      "Epoch 16/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.3458 - loss: 0.0276\n",
      "Epoch 17/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.3594 - loss: 0.0272\n",
      "Epoch 18/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.3501 - loss: 0.0266\n",
      "Epoch 19/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.3526 - loss: 0.0261\n",
      "Epoch 20/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.3400 - loss: 0.0258\n"
     ]
    }
   ],
   "source": [
    "ANN_model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Train model\n",
    "history = ANN_model1.fit(word1_onehot, word2_onehot, epochs=20, batch_size=50,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:21:01.668025Z",
     "start_time": "2025-01-21T03:21:01.646720Z"
    }
   },
   "outputs": [],
   "source": [
    "#We will see what the 1st hidden layer output representation of the data  \n",
    "# to predict the hidden layer activations, \n",
    "# let's rewrite first layer of our model and give it the weights from fully trained previous model\n",
    "model1_hidden = Sequential()\n",
    "d1 = Dense(10, input_dim=word1_onehot.shape[1])\n",
    "model1_hidden.add(d1)\n",
    "model1_hidden.layers[0].set_weights(ANN_model1.layers[0].get_weights())\n",
    "#model1_hidden.add(Dense(10, input_dim=word1_onehot.shape[1], weights=ANN_model1.layers[0].get_weights()))\n",
    "model1_hidden.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:21:03.436409Z",
     "start_time": "2025-01-21T03:21:03.219598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "The hidden layer output for every record - Shape of it \n",
      " (5351, 10)\n",
      "Few five records from hidden layer \n",
      " [[0.8502008  0.8412782  0.83450085 0.87213963 0.86522204 0.8721876\n",
      "  0.83738834 0.839684   0.854408   0.8659704 ]\n",
      " [0.8502008  0.8412782  0.83450085 0.87213963 0.86522204 0.8721876\n",
      "  0.83738834 0.839684   0.854408   0.8659704 ]\n",
      " [0.8502008  0.8412782  0.83450085 0.87213963 0.86522204 0.8721876\n",
      "  0.83738834 0.839684   0.854408   0.8659704 ]\n",
      " [0.8502008  0.8412782  0.83450085 0.87213963 0.86522204 0.8721876\n",
      "  0.83738834 0.839684   0.854408   0.8659704 ]\n",
      " [0.8502008  0.8412782  0.83450085 0.87213963 0.86522204 0.8721876\n",
      "  0.83738834 0.839684   0.854408   0.8659704 ]]\n"
     ]
    }
   ],
   "source": [
    "# Getting the hidden layer activations\n",
    "model1_hidden_output = model1_hidden.predict(word1_onehot)\n",
    "#peak into our hidden layer activations\n",
    "print(\"The hidden layer output for every record - Shape of it \\n\", model1_hidden_output.shape)\n",
    "print(\"Few five records from hidden layer \\n\",model1_hidden_output[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:21:22.648252Z",
     "start_time": "2025-01-21T03:21:22.643409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2_hidden_append Shape (5351, 149)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We append the input words of the words2 column in the output of the h1 layer,this gives us the combined input representation\n",
    "\"\"\"\n",
    "word2_hidden_append = np.append(model1_hidden_output,word2_onehot, axis=1)\n",
    "print(\"word2_hidden_append Shape\", word2_hidden_append.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:21:24.285661Z",
     "start_time": "2025-01-21T03:21:24.247411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">139</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,529</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m139\u001b[0m)            │         \u001b[38;5;34m1,529\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,029</span> (11.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,029\u001b[0m (11.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,029</span> (11.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,029\u001b[0m (11.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ANN_model2 = Sequential()\n",
    "ANN_model2.add(Dense(10, input_dim=word2_hidden_append.shape[1], activation='sigmoid'))\n",
    "ANN_model2.add(Dense(word3_onehot.shape[1], activation='softmax'))\n",
    "ANN_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:21:31.999889Z",
     "start_time": "2025-01-21T03:21:27.551704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.6167\n",
      "Epoch 2/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.0610 - loss: 0.2860 \n",
      "Epoch 3/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2509 - loss: 0.1416  \n",
      "Epoch 4/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.2461 - loss: 0.0911\n",
      "Epoch 5/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.2414 - loss: 0.0683\n",
      "Epoch 6/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.2517 - loss: 0.0561\n",
      "Epoch 7/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.2336 - loss: 0.0489\n",
      "Epoch 8/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.2404 - loss: 0.0441\n",
      "Epoch 9/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.2448 - loss: 0.0407\n",
      "Epoch 10/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.2468 - loss: 0.0385\n",
      "Epoch 11/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.2372 - loss: 0.0370\n",
      "Epoch 12/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.2320 - loss: 0.0356\n",
      "Epoch 13/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.2470 - loss: 0.0345\n",
      "Epoch 14/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.2494 - loss: 0.0338\n",
      "Epoch 15/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.2304 - loss: 0.0336\n",
      "Epoch 16/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.2364 - loss: 0.0330\n",
      "Epoch 17/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.2482 - loss: 0.0324\n",
      "Epoch 18/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.2397 - loss: 0.0323\n",
      "Epoch 19/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.2480 - loss: 0.0315\n",
      "Epoch 20/20\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.2332 - loss: 0.0316\n"
     ]
    }
   ],
   "source": [
    "ANN_model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Train model\n",
    "history = ANN_model2.fit(word2_hidden_append, word3_onehot, epochs=20, batch_size=50,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:24:49.468231Z",
     "start_time": "2025-01-21T03:24:49.462741Z"
    }
   },
   "outputs": [],
   "source": [
    "# A predict function that takes input word1 and word2; and predict word3 \n",
    "#1. take the input word , and represent them using digits from the word_indices dictonary values\n",
    "#2. getting the intermediate hidden nodes for word1\n",
    "#3. appending hidden activations with word2 as final test set\n",
    "#4. prediction on this test set\n",
    "def two_step_pred(words_in):\n",
    "\n",
    "    index_input=word_indices[words_in[0]]\n",
    "    indices_in = keras.utils.to_categorical(index_input, num_classes=len(word_indices))\n",
    "    indices_in=indices_in.reshape(1,len(word_indices))\n",
    "    h1_test = model1_hidden.predict(indices_in) # getting our intermediate hidden activations from model1h\n",
    "    \n",
    "    \n",
    "    index_input2=word_indices[words_in[1]]\n",
    "    indices_in2 = keras.utils.to_categorical(index_input2, num_classes=len(word_indices))\n",
    "    indices_in2= indices_in2.reshape(1,len(word_indices))\n",
    "    X2_test = np.append(h1_test, indices_in2, axis=1) #preparing final test data by appending hidden with word2\n",
    "    \n",
    "    predict_x = ANN_model2.predict(X2_test) #predicting final output from model2\n",
    "    yhat=np.argmax(predict_x,axis=1)\n",
    "    \n",
    "    print(\"Input words --> \", words_in)\n",
    "    print(\"Predicted word --> \", indices_words[yhat[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:22:46.701183Z",
     "start_time": "2025-01-21T03:22:46.680467Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:24:50.254600Z",
     "start_time": "2025-01-21T03:24:50.062005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
      "Input words -->  ['love', 'it']\n",
      "Predicted word -->  when\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Input words -->  ['love', 'to']\n",
      "Predicted word -->  when\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Input words -->  ['love', 'the']\n",
      "Predicted word -->  when\n"
     ]
    }
   ],
   "source": [
    "two_step_pred(['love', 'it'])\n",
    "two_step_pred(['love', 'to'])\n",
    "two_step_pred(['love', 'the'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:25:02.874143Z",
     "start_time": "2025-01-21T03:25:02.813904Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudarsun/venv/da5401/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m24\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m12\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> (144.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36\u001b[0m (144.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> (144.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36\u001b[0m (144.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(4, use_bias=False, input_shape=(2,2)))\n",
    "model.add(Dense(3, use_bias=False, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:25:03.894850Z",
     "start_time": "2025-01-21T03:25:03.846796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m28\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m15\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43</span> (172.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m43\u001b[0m (172.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43</span> (172.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m43\u001b[0m (172.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(4, input_shape=(2,2)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:25:22.966679Z",
     "start_time": "2025-01-21T03:25:22.902852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_2 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m28\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m15\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43</span> (172.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m43\u001b[0m (172.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43</span> (172.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m43\u001b[0m (172.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(4, input_shape=(4,2)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word prediction using RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:25:27.913709Z",
     "start_time": "2025-01-21T03:25:27.902972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word1_word2_onehot shape (5351, 2, 139)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_158724/3906608908.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word1_word2[i] = word1_word2[i].map(word_indices)\n",
      "/tmp/ipykernel_158724/3906608908.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  word1_word2[i] = word1_word2[i].map(word_indices)\n"
     ]
    }
   ],
   "source": [
    "word1_word2 = input_3gram[['word1','word2']]\n",
    "for i in list(word1_word2.columns.values):\n",
    "    word1_word2[i] = word1_word2[i].map(word_indices)\n",
    "\n",
    "word1_word2=np.array(word1_word2)\n",
    "#The same data is reshaped with similar structure but appended with 1 value to make it 3d array\n",
    "word1_word2=np.reshape(word1_word2,(word1_word2.shape[0],2,1))\n",
    "word1_word2_onehot = keras.utils.to_categorical(np.array(word1_word2), num_classes=len(word_indices))\n",
    "print(\"word1_word2_onehot shape\", word1_word2_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:26:16.364075Z",
     "start_time": "2025-01-21T03:26:16.360221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time steps 2\n",
      "Input nodes 139\n",
      "output nodes 139\n"
     ]
    }
   ],
   "source": [
    "print(\"time steps\" , word1_word2_onehot.shape[1])\n",
    "print(\"Input nodes\" , word1_word2_onehot.shape[2])\n",
    "print(\"output nodes\" , word3_onehot.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:26:18.072145Z",
     "start_time": "2025-01-21T03:26:18.003744Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudarsun/venv/da5401/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">139</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,309</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_3 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m5,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m139\u001b[0m)            │         \u001b[38;5;34m4,309\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,409</span> (36.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,409\u001b[0m (36.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,409</span> (36.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,409\u001b[0m (36.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_rnn = Sequential()\n",
    "#model.add(SimpleRNN('number of hidden nodes in each rnn cell', input_shape=(timesteps, input_data_dim)))\n",
    "model_rnn.add(SimpleRNN(30, input_shape=(word1_word2_onehot.shape[1],word1_word2_onehot.shape[2]))) \n",
    "model_rnn.add(Dense(word3_onehot.shape[1], activation='softmax'))\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:26:30.193893Z",
     "start_time": "2025-01-21T03:26:20.424379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.3328 - loss: 4.3155\n",
      "Epoch 2/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4517 - loss: 2.9260\n",
      "Epoch 3/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5337 - loss: 2.4618\n",
      "Epoch 4/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5498 - loss: 2.1513\n",
      "Epoch 5/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5933 - loss: 1.8784\n",
      "Epoch 6/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6034 - loss: 1.7803\n",
      "Epoch 7/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6351 - loss: 1.6178\n",
      "Epoch 8/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6470 - loss: 1.5269\n",
      "Epoch 9/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6599 - loss: 1.4490\n",
      "Epoch 10/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6594 - loss: 1.4156\n",
      "Epoch 11/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6597 - loss: 1.3768\n",
      "Epoch 12/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6632 - loss: 1.3446\n",
      "Epoch 13/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6528 - loss: 1.3499\n",
      "Epoch 14/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.6623 - loss: 1.2828\n",
      "Epoch 15/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.6623 - loss: 1.2507\n",
      "Epoch 16/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6658 - loss: 1.2375\n",
      "Epoch 17/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.6661 - loss: 1.2081\n",
      "Epoch 18/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.6718 - loss: 1.1889\n",
      "Epoch 19/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.6625 - loss: 1.1993\n",
      "Epoch 20/20\n",
      "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.6605 - loss: 1.1992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x74b0cc07fbf0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile network\n",
    "model_rnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model_rnn.fit(word1_word2_onehot, word3_onehot, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:29:19.731060Z",
     "start_time": "2025-01-21T03:29:19.726787Z"
    }
   },
   "outputs": [],
   "source": [
    "def rnn_word_pred(in_text):\n",
    "    print(\"Input is - \" , in_text)\n",
    "    encoded = [word_indices[i] for i in in_text]\n",
    "    encoded = np.array(encoded).reshape(1,2,1)\n",
    "    encoded =keras.utils.to_categorical(np.array(encoded), num_classes=len(word_indices))\n",
    "    ypred_x = model_rnn.predict(encoded, verbose=0)[0]\n",
    "    ypred = np.argmax(ypred_x, axis=0)  \n",
    "    print(\"Output is --> \" ,indices_words[ypred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:29:20.641169Z",
     "start_time": "2025-01-21T03:29:20.534432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is -  ['love', 'it']\n",
      "Output is -->  when\n",
      "Input is -  ['love', 'to']\n",
      "Output is -->  see\n",
      "Input is -  ['love', 'the']\n",
      "Output is -->  way\n"
     ]
    }
   ],
   "source": [
    "rnn_word_pred(['love', 'it'])\n",
    "rnn_word_pred(['love', 'to'])\n",
    "rnn_word_pred(['love', 'the'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN for Long Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:29:50.315074Z",
     "start_time": "2025-01-21T03:29:50.309809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a,combination,of\n",
      "a,combination,of\n",
      "a,combination,of\n",
      "a,co\n",
      "\n",
      "and,according,to\n",
      "and,according,to\n",
      "and,according,to\n",
      "and,according,to\n",
      "and,according,to\n",
      "and,according,to\n",
      "and,according,to\n",
      "and,according,to\n",
      "and,according,to\n",
      "and,according,to\n",
      "and,addresses,of\n",
      "and,adherence,to\n",
      "and,advocates,for\n",
      "and,aerospac\n"
     ]
    }
   ],
   "source": [
    "longseq_3gram = open(Data_path+'/Long_sequence_3gram.csv').read().lower()\n",
    "print(longseq_3gram[495:551])\n",
    "print(longseq_3gram[30615:30850])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:30:00.613158Z",
     "start_time": "2025-01-21T03:30:00.607452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "a combination of\n",
      "a combination of\n",
      "a combination of\n",
      "a combination of\n",
      "a combination of\n",
      "a combination of\n",
      "a combination of\n",
      "a combination of\n",
      "a combination of\n",
      "a combination of\n",
      "a combination of\n",
      "a combination of\n",
      "a combination of\n",
      "a combination of\n",
      "a combination of\n",
      "\n",
      "and according to\n",
      "and according to\n",
      "and according to\n",
      "and according to\n",
      "and according to\n",
      "and according to\n",
      "and according to\n",
      "and according to\n",
      "and according to\n",
      "and according to\n",
      "and addresses \n"
     ]
    }
   ],
   "source": [
    "#Replace comma with space\n",
    "longseq_3gram1= longseq_3gram.replace(',',' ').replace('\\r','')\n",
    "print(longseq_3gram1[495:750])\n",
    "print(longseq_3gram1[30615:30800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:30:07.200980Z",
     "start_time": "2025-01-21T03:30:07.191896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Characters in the text \n",
      "  ['\\n', ' ', \"'\", '(', '-', '.', '/', '0', '1', '3', '7', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      " Character after removing newline symbol '\\n' [' ', \"'\", '(', '-', '.', '/', '0', '1', '3', '7', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      " overall chars count 37\n"
     ]
    }
   ],
   "source": [
    "#Unique characters in our dataset we then sort it\n",
    "chars = sorted(list(set(longseq_3gram1)))\n",
    "print(\"Unique Characters in the text \\n \",chars)\n",
    "#\\n is character string for new line, we dont need that in our dictionary of chars\n",
    "chars.remove('\\n')\n",
    "print(\"\\n Character after removing newline symbol \\'\\\\n\\'\",chars)\n",
    "print(\"\\n overall chars count\", len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:30:07.555431Z",
     "start_time": "2025-01-21T03:30:07.550769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters to indices dictionary\n",
      " {' ': 0, \"'\": 1, '(': 2, '-': 3, '.': 4, '/': 5, '0': 6, '1': 7, '3': 8, '7': 9, '9': 10, 'a': 11, 'b': 12, 'c': 13, 'd': 14, 'e': 15, 'f': 16, 'g': 17, 'h': 18, 'i': 19, 'j': 20, 'k': 21, 'l': 22, 'm': 23, 'n': 24, 'o': 25, 'p': 26, 'q': 27, 'r': 28, 's': 29, 't': 30, 'u': 31, 'v': 32, 'w': 33, 'x': 34, 'y': 35, 'z': 36}\n",
      "indices to char dictionary\n",
      " {0: ' ', 1: \"'\", 2: '(', 3: '-', 4: '.', 5: '/', 6: '0', 7: '1', 8: '3', 9: '7', 10: '9', 11: 'a', 12: 'b', 13: 'c', 14: 'd', 15: 'e', 16: 'f', 17: 'g', 18: 'h', 19: 'i', 20: 'j', 21: 'k', 22: 'l', 23: 'm', 24: 'n', 25: 'o', 26: 'p', 27: 'q', 28: 'r', 29: 's', 30: 't', 31: 'u', 32: 'v', 33: 'w', 34: 'x', 35: 'y', 36: 'z'}\n",
      "unique chars:  {37}\n"
     ]
    }
   ],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "print(\"characters to indices dictionary\\n\", char_indices)\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "print(\"indices to char dictionary\\n\", indices_char)\n",
    "print('unique chars: ', {len(chars)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Char to index on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:30:11.560157Z",
     "start_time": "2025-01-21T03:30:11.515618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a bewildering array  [11, 0, 12, 15, 33, 19, 22, 14, 15, 28, 19, 24, 17, 0, 11, 28, 28, 11, 35, 0]\n",
      "a celebration of  [11, 0, 12, 15, 24, 15, 16, 19, 13, 19, 11, 28, 35, 0, 25, 16, 0]\n",
      "a co-director of  [11, 0, 12, 15, 33, 19, 22, 14, 15, 28, 19, 24, 17, 0, 32, 11, 28, 19, 15, 30, 35, 0]\n",
      "a declaration of  [11, 0, 12, 19, 30, 30, 15, 28, 29, 33, 15, 15, 30, 0, 23, 25, 23, 15, 24, 30, 0]\n",
      "a significant risk  [11, 0, 29, 19, 17, 24, 19, 16, 19, 13, 11, 24, 30, 0, 28, 19, 29, 21, 0]\n",
      "been designed as  [12, 15, 15, 24, 0, 14, 15, 29, 19, 17, 24, 15, 14, 0, 11, 29, 0]\n",
      "from anywhere on  [16, 28, 25, 23, 0, 11, 24, 35, 33, 18, 15, 28, 15, 0, 25, 24, 0]\n",
      "Number of sentences  30307\n"
     ]
    }
   ],
   "source": [
    "data = longseq_3gram1.splitlines()\n",
    "##Adding a space at the end\n",
    "data = [i+' ' for i in data]\n",
    "\n",
    "##mapping our data into numbers\n",
    "sentences = [[char_indices[j] for j in i] for i in data ]\n",
    "print(data[0], sentences[0])\n",
    "print(data[10], sentences[1])\n",
    "print(data[20], sentences[2])\n",
    "print(data[100], sentences[3])\n",
    "print(data[400], sentences[400])\n",
    "print(data[4000], sentences[4000])\n",
    "print(data[9000], sentences[9000])\n",
    "##Number of sentences\n",
    "print(\"Number of sentences \", len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the sentences to RNN friendly data which can be used to generate new sequences\n",
    "\n",
    "**Take one sentence, iterate through it till the length of sentence is reached:**\n",
    "\n",
    "* **Step 1** 0:0+14: X; and 14th position: y >> observation 1\n",
    "* **Step 2** 1:14: X; and 15th position: y >> observation 2\n",
    "* **Step 3** …we do this till the length of sentence is reached\n",
    "\n",
    "Take next sentence and repeat the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:30:15.183486Z",
     "start_time": "2025-01-21T03:30:14.968525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142142, 142142)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since all the sentences may not be of same length,it is neccessary to make them consistent when passing to keras\n",
    "#We select a sequence length\n",
    "Seq_ln = 14\n",
    "X = []\n",
    "y = []\n",
    "for i in sentences:\n",
    "    for j in range(len(i)-Seq_ln):\n",
    "        X.append(i[j:j+Seq_ln])\n",
    "        y.append(i[j+Seq_ln])\n",
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:30:16.846568Z",
     "start_time": "2025-01-21T03:30:16.841026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data[0:2]= ['a bewildering array ', 'a beneficiary of ']\n",
      "sentences[0:2]= [[11, 0, 12, 15, 33, 19, 22, 14, 15, 28, 19, 24, 17, 0, 11, 28, 28, 11, 35, 0], [11, 0, 12, 15, 24, 15, 16, 19, 13, 19, 11, 28, 35, 0, 25, 16, 0]]\n",
      "X[ 0 ]= [11, 0, 12, 15, 33, 19, 22, 14, 15, 28, 19, 24, 17, 0] y[ 0 ]= 11\n",
      "X[ 1 ]= [0, 12, 15, 33, 19, 22, 14, 15, 28, 19, 24, 17, 0, 11] y[ 1 ]= 28\n",
      "X[ 2 ]= [12, 15, 33, 19, 22, 14, 15, 28, 19, 24, 17, 0, 11, 28] y[ 2 ]= 28\n",
      "X[ 3 ]= [15, 33, 19, 22, 14, 15, 28, 19, 24, 17, 0, 11, 28, 28] y[ 3 ]= 11\n",
      "X[ 4 ]= [33, 19, 22, 14, 15, 28, 19, 24, 17, 0, 11, 28, 28, 11] y[ 4 ]= 35\n",
      "X[ 5 ]= [19, 22, 14, 15, 28, 19, 24, 17, 0, 11, 28, 28, 11, 35] y[ 5 ]= 0\n",
      "X[ 6 ]= [11, 0, 12, 15, 24, 15, 16, 19, 13, 19, 11, 28, 35, 0] y[ 6 ]= 25\n",
      "X[ 7 ]= [0, 12, 15, 24, 15, 16, 19, 13, 19, 11, 28, 35, 0, 25] y[ 7 ]= 16\n",
      "X[ 8 ]= [12, 15, 24, 15, 16, 19, 13, 19, 11, 28, 35, 0, 25, 16] y[ 8 ]= 0\n",
      "X[ 9 ]= [11, 0, 12, 15, 33, 19, 22, 14, 15, 28, 19, 24, 17, 0] y[ 9 ]= 32\n",
      "X[ 10 ]= [0, 12, 15, 33, 19, 22, 14, 15, 28, 19, 24, 17, 0, 32] y[ 10 ]= 11\n",
      "X[ 11 ]= [12, 15, 33, 19, 22, 14, 15, 28, 19, 24, 17, 0, 32, 11] y[ 11 ]= 28\n",
      "X[ 12 ]= [15, 33, 19, 22, 14, 15, 28, 19, 24, 17, 0, 32, 11, 28] y[ 12 ]= 19\n",
      "X[ 13 ]= [33, 19, 22, 14, 15, 28, 19, 24, 17, 0, 32, 11, 28, 19] y[ 13 ]= 15\n",
      "X[ 14 ]= [19, 22, 14, 15, 28, 19, 24, 17, 0, 32, 11, 28, 19, 15] y[ 14 ]= 30\n",
      "X[ 15 ]= [22, 14, 15, 28, 19, 24, 17, 0, 32, 11, 28, 19, 15, 30] y[ 15 ]= 35\n",
      "X[ 16 ]= [14, 15, 28, 19, 24, 17, 0, 32, 11, 28, 19, 15, 30, 35] y[ 16 ]= 0\n",
      "X[ 17 ]= [11, 0, 12, 19, 30, 30, 15, 28, 29, 33, 15, 15, 30, 0] y[ 17 ]= 23\n",
      "X[ 18 ]= [0, 12, 19, 30, 30, 15, 28, 29, 33, 15, 15, 30, 0, 23] y[ 18 ]= 25\n",
      "X[ 19 ]= [12, 19, 30, 30, 15, 28, 29, 33, 15, 15, 30, 0, 23, 25] y[ 19 ]= 23\n"
     ]
    }
   ],
   "source": [
    "print(\"data[0:2]=\", data[0:2])\n",
    "print(\"sentences[0:2]=\", sentences[0:2])\n",
    "\n",
    "for i in range (0,20):\n",
    "    print(\"X[\",i,\"]=\", X[i],\"y[\",i,\"]=\", y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:30:17.896400Z",
     "start_time": "2025-01-21T03:30:17.726383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142142, 14, 37)\n"
     ]
    }
   ],
   "source": [
    "#The first row is the X's first row up to 14 character\n",
    "#The second row is the X's first row starting from second character up to 14 character\n",
    "#The third row is the X's first row starting from third character up to 14 character and so on \n",
    "X=np.array(X)\n",
    "X1=np.reshape(X,(X.shape[0],X.shape[1],1))\n",
    "X1=keras.utils.to_categorical(np.array(X1), num_classes=len(char_indices))\n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:30:20.036914Z",
     "start_time": "2025-01-21T03:30:20.015679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142142, 37)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target Variable\n",
    "y[:10]\n",
    "#Reshapig our label for model\n",
    "y1 = np.array(y)\n",
    "# one hot encode outputs\n",
    "y1 = keras.utils.to_categorical(np.array(y), num_classes=len(char_indices))\n",
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:30:20.792945Z",
     "start_time": "2025-01-21T03:30:20.701794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (113713, 14, 37)\n",
      "y_train.shape (113713, 37)\n",
      "X_test.shape (28429, 14, 37)\n",
      "y_test.shape (28429, 37)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.20)\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"y_train.shape\", y_train.shape)\n",
    "print(\"X_test.shape\", X_test.shape)\n",
    "print(\"y_test.shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:30:21.509052Z",
     "start_time": "2025-01-21T03:30:21.445951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">629</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ simple_rnn_4 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m)             │           \u001b[38;5;34m629\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,493</span> (5.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,493\u001b[0m (5.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,493</span> (5.83 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,493\u001b[0m (5.83 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#building the model\n",
    "model_RNN2 = Sequential()\n",
    "##model.add(SimpleRNN('number of hidden nodes in each rnn cell', input_shape=(timesteps, data_dim)))\n",
    "model_RNN2.add(SimpleRNN(16, input_shape=(X_train.shape[1], X_train.shape[2]))) \n",
    "model_RNN2.add(Dense(len(char_indices)))\n",
    "model_RNN2.add(Activation('softmax'))\n",
    "model_RNN2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:30:54.355599Z",
     "start_time": "2025-01-21T03:30:35.527892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.3170 - loss: 2.4831 - val_accuracy: 0.4278 - val_loss: 1.9490\n",
      "Epoch 2/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4363 - loss: 1.9299 - val_accuracy: 0.4608 - val_loss: 1.8482\n",
      "Epoch 3/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4621 - loss: 1.8428 - val_accuracy: 0.4728 - val_loss: 1.8056\n",
      "Epoch 4/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4726 - loss: 1.7989 - val_accuracy: 0.4728 - val_loss: 1.7786\n",
      "Epoch 5/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4763 - loss: 1.7752 - val_accuracy: 0.4831 - val_loss: 1.7603\n",
      "Epoch 6/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4803 - loss: 1.7594 - val_accuracy: 0.4891 - val_loss: 1.7430\n",
      "Epoch 7/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.4879 - loss: 1.7317 - val_accuracy: 0.4868 - val_loss: 1.7281\n",
      "Epoch 8/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4862 - loss: 1.7248 - val_accuracy: 0.4887 - val_loss: 1.7208\n",
      "Epoch 9/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.4916 - loss: 1.7194 - val_accuracy: 0.4945 - val_loss: 1.7091\n",
      "Epoch 10/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4928 - loss: 1.7078 - val_accuracy: 0.4920 - val_loss: 1.7027\n",
      "Epoch 11/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4964 - loss: 1.6943 - val_accuracy: 0.4952 - val_loss: 1.6919\n",
      "Epoch 12/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.4977 - loss: 1.6880 - val_accuracy: 0.4996 - val_loss: 1.6879\n",
      "Epoch 13/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5001 - loss: 1.6799 - val_accuracy: 0.4991 - val_loss: 1.6825\n",
      "Epoch 14/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5001 - loss: 1.6822 - val_accuracy: 0.4953 - val_loss: 1.6826\n",
      "Epoch 15/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.5020 - loss: 1.6706 - val_accuracy: 0.5046 - val_loss: 1.6746\n",
      "Epoch 16/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.5018 - loss: 1.6734 - val_accuracy: 0.5016 - val_loss: 1.6722\n",
      "Epoch 17/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.5026 - loss: 1.6758 - val_accuracy: 0.5052 - val_loss: 1.6642\n",
      "Epoch 18/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5067 - loss: 1.6547 - val_accuracy: 0.5047 - val_loss: 1.6623\n",
      "Epoch 19/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.5042 - loss: 1.6589 - val_accuracy: 0.5033 - val_loss: 1.6611\n",
      "Epoch 20/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5084 - loss: 1.6500 - val_accuracy: 0.5065 - val_loss: 1.6574\n",
      "Epoch 21/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.5103 - loss: 1.6439 - val_accuracy: 0.5080 - val_loss: 1.6535\n",
      "Epoch 22/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5072 - loss: 1.6516 - val_accuracy: 0.5067 - val_loss: 1.6568\n",
      "Epoch 23/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5077 - loss: 1.6499 - val_accuracy: 0.5070 - val_loss: 1.6506\n",
      "Epoch 24/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5083 - loss: 1.6443 - val_accuracy: 0.5061 - val_loss: 1.6494\n",
      "Epoch 25/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5121 - loss: 1.6391 - val_accuracy: 0.5080 - val_loss: 1.6472\n",
      "Epoch 26/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.5095 - loss: 1.6454 - val_accuracy: 0.5054 - val_loss: 1.6435\n",
      "Epoch 27/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5120 - loss: 1.6372 - val_accuracy: 0.5087 - val_loss: 1.6414\n",
      "Epoch 28/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5082 - loss: 1.6501 - val_accuracy: 0.5087 - val_loss: 1.6415\n",
      "Epoch 29/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5129 - loss: 1.6367 - val_accuracy: 0.5081 - val_loss: 1.6413\n",
      "Epoch 30/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5117 - loss: 1.6368 - val_accuracy: 0.5080 - val_loss: 1.6384\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The filename must end in `.weights.h5`. Received: filepath=char_rnn_model_weights_v1.hdf5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# fit network\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model_RNN2\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test))\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel_RNN2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchar_rnn_model_weights_v1.hdf5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/da5401/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/venv/da5401/lib/python3.12/site-packages/keras/src/saving/saving_api.py:222\u001b[0m, in \u001b[0;36msave_weights\u001b[0;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.saving.save_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_weights\u001b[39m(model, filepath, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe filename must end in `.weights.h5`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m         exists \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(filepath)\n",
      "\u001b[0;31mValueError\u001b[0m: The filename must end in `.weights.h5`. Received: filepath=char_rnn_model_weights_v1.hdf5"
     ]
    }
   ],
   "source": [
    "# compile network\n",
    "model_RNN2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model_RNN2.fit(X_train, y_train, epochs=30, verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RNN2.save_weights(\"char_rnn_model_weights_v1.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:33:23.685472Z",
     "start_time": "2025-01-21T03:32:38.409827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.5100 - loss: 1.6418\n",
      "Epoch 2/2\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.5104 - loss: 1.6341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x74afd2dbcf50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightsfile_model_RNN2= \"./Pre_trained_models/char_rnn_model_weights_v1.hdf5\"\n",
    "model_RNN2.load_weights(weightsfile_model_RNN2)\n",
    "\n",
    "# compile network\n",
    "model_RNN2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model_RNN2.fit(X_train, y_train, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:37:00.671007Z",
     "start_time": "2025-01-21T03:37:00.665726Z"
    }
   },
   "outputs": [],
   "source": [
    "#function to prepare test input\n",
    "def prepare_input(in_text):\n",
    "    X1 = np.array([char_indices[i] for i in in_text]).reshape(1,14,1)\n",
    "    X1=keras.utils.to_categorical(np.array(X1), num_classes=len(char_indices))\n",
    "    return(X1)\n",
    "#function to loop our preditions\n",
    "def complete_pred(in_text):\n",
    "    #original_text = in_text\n",
    "    #generated = in_text\n",
    "    completion = ''\n",
    "    while True:\n",
    "        x = prepare_input(in_text)\n",
    "        pred_x = model_RNN2.predict(x, verbose=0)[0]\n",
    "        pred = np.argmax(pred_x, axis=0)\n",
    "        next_char = indices_char[pred]\n",
    "\n",
    "        in_text = in_text[1:] + next_char\n",
    "        completion += next_char\n",
    "\n",
    "        if len(completion)> 20 or next_char == ' ':\n",
    "            return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:37:38.568537Z",
     "start_time": "2025-01-21T03:37:38.011019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text --> officials say  \n",
      "predicted word --->  to \n",
      "Input text --> how dangerous  \n",
      "predicted output --->  of \n",
      "Input text --> determine the  \n",
      "predicted output --->  bete \n",
      "Input text --> whatever they  \n",
      "predicted output --->  the \n",
      "Input text --> democrats and  \n",
      "predicted output --->  the \n"
     ]
    }
   ],
   "source": [
    "in_text = 'officials say '\n",
    "out_word = complete_pred(in_text)\n",
    "print(\"Input text -->\", in_text, \"\\npredicted word ---> \", out_word)\n",
    "in_text = 'how dangerous '\n",
    "out_word = complete_pred(in_text)\n",
    "print(\"Input text -->\", in_text, \"\\npredicted output ---> \", out_word)\n",
    "in_text = 'determine the '\n",
    "out_word = complete_pred(in_text)\n",
    "print(\"Input text -->\", in_text, \"\\npredicted output ---> \", out_word)\n",
    "in_text = 'whatever they '\n",
    "out_word = complete_pred(in_text)\n",
    "print(\"Input text -->\", in_text, \"\\npredicted output ---> \", out_word)\n",
    "in_text = 'democrats and '\n",
    "out_word = complete_pred(in_text)\n",
    "print(\"Input text -->\", in_text, \"\\npredicted output ---> \", out_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:37:48.100924Z",
     "start_time": "2025-01-21T03:37:47.945532Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudarsun/venv/da5401/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">84,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,773</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m84,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m)             │         \u001b[38;5;34m4,773\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,765</span> (350.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m89,765\u001b[0m (350.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,765</span> (350.64 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m89,765\u001b[0m (350.64 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#building the model\n",
    "model_LSTM = Sequential()\n",
    "#model1.add(LSTM('number of hidden nodes in each rnn cell', input_shape=(timesteps, data_dim)))\n",
    "model_LSTM.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]))) \n",
    "model_LSTM.add(Dense(len(char_indices)))\n",
    "model_LSTM.add(Activation('softmax'))\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:37:53.094461Z",
     "start_time": "2025-01-21T03:37:48.910230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.3607 - loss: 2.2436\n",
      "Epoch 2/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.5180 - loss: 1.6185\n",
      "Epoch 3/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.5756 - loss: 1.4250\n",
      "Epoch 4/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.6124 - loss: 1.2996\n",
      "Epoch 5/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.6410 - loss: 1.2044\n",
      "Epoch 6/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 7ms/step - accuracy: 0.6632 - loss: 1.1280\n",
      "Epoch 7/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.6853 - loss: 1.0576\n",
      "Epoch 8/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.6975 - loss: 1.0094\n",
      "Epoch 9/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.7095 - loss: 0.9673\n",
      "Epoch 10/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.7204 - loss: 0.9304\n",
      "Epoch 11/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.7292 - loss: 0.8963\n",
      "Epoch 12/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.7397 - loss: 0.8612\n",
      "Epoch 13/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.7479 - loss: 0.8272\n",
      "Epoch 14/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.7524 - loss: 0.8113\n",
      "Epoch 15/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.7617 - loss: 0.7813\n",
      "Epoch 16/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.7672 - loss: 0.7631\n",
      "Epoch 17/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.7700 - loss: 0.7496\n",
      "Epoch 18/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.7765 - loss: 0.7238\n",
      "Epoch 19/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.7828 - loss: 0.7063\n",
      "Epoch 20/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.7866 - loss: 0.6947\n",
      "Epoch 21/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.7899 - loss: 0.6791\n",
      "Epoch 22/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.7917 - loss: 0.6657\n",
      "Epoch 23/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.7952 - loss: 0.6522\n",
      "Epoch 24/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.7952 - loss: 0.6501\n",
      "Epoch 25/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.7985 - loss: 0.6412\n",
      "Epoch 26/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8042 - loss: 0.6197\n",
      "Epoch 27/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8044 - loss: 0.6193\n",
      "Epoch 28/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.8092 - loss: 0.6062\n",
      "Epoch 29/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.8093 - loss: 0.6001\n",
      "Epoch 30/30\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8119 - loss: 0.5969\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The filename must end in `.weights.h5`. Received: filepath=char_LSTM_model_weights_v1.hdf5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# fit network\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model_LSTM\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mmodel_LSTM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchar_LSTM_model_weights_v1.hdf5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/da5401/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/venv/da5401/lib/python3.12/site-packages/keras/src/saving/saving_api.py:222\u001b[0m, in \u001b[0;36msave_weights\u001b[0;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.saving.save_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_weights\u001b[39m(model, filepath, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe filename must end in `.weights.h5`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m         )\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m         exists \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(filepath)\n",
      "\u001b[0;31mValueError\u001b[0m: The filename must end in `.weights.h5`. Received: filepath=char_LSTM_model_weights_v1.hdf5"
     ]
    }
   ],
   "source": [
    "# compile network\n",
    "model_LSTM.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model_LSTM.fit(X_train, y_train, epochs=30, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LSTM.save_weights(\"char_LSTM_model_weights_v1.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:38:35.746705Z",
     "start_time": "2025-01-21T03:38:13.305804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.7973 - loss: 0.6946\n",
      "Epoch 2/2\n",
      "\u001b[1m3554/3554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.8025 - loss: 0.6485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x74b048388440>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightsfile_model_LSTM=\"./Pre_trained_models/char_LSTM_model_weights_v1.hdf5\"\n",
    "model_LSTM.load_weights( weightsfile_model_LSTM)\n",
    "\n",
    "# compile network\n",
    "model_LSTM.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model_LSTM.fit(X_train, y_train,epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:38:57.729076Z",
     "start_time": "2025-01-21T03:38:57.723161Z"
    }
   },
   "outputs": [],
   "source": [
    "#function to prepare test input\n",
    "def prepare_input1(in_text):\n",
    "    X1 = np.array([char_indices[i] for i in in_text]).reshape(1,14,1)\n",
    "    X1= keras.utils.to_categorical(np.array(X1), num_classes=len(char_indices))\n",
    "    return(X1)\n",
    "#function to loop our preditions\n",
    "def complete_pred1(in_text):\n",
    "    #original_text = in_text\n",
    "    #generated = in_text\n",
    "    completion = ''\n",
    "    while True:\n",
    "        x = prepare_input1(in_text)\n",
    "        pred_x = model_LSTM.predict(x, verbose=0)[0]\n",
    "        pred = np.argmax(pred_x, axis=0)\n",
    "        next_char = indices_char[pred]\n",
    "\n",
    "        in_text = in_text[1:] + next_char\n",
    "        completion += next_char\n",
    "\n",
    "        if len(completion)> 20 or next_char == ' ':\n",
    "            return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:40:14.311399Z",
     "start_time": "2025-01-21T03:40:13.204136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text --> the emergence  ; predicted output --->  of \n",
      "Input text --> officials say  ; predicted output --->  they \n",
      "Input text --> and sentenced  ; predicted output --->  to \n",
      "Input text --> a combination  ; predicted output --->  of \n",
      "Input text --> and according  ; predicted output --->  to \n",
      "Input text --> department of  ; predicted output --->  the \n",
      "Input text --> democrats and  ; predicted output --->  republicans \n"
     ]
    }
   ],
   "source": [
    "in_text = 'the emergence '\n",
    "out_word = complete_pred1(in_text)\n",
    "print(\"Input text -->\", in_text, \"; predicted output ---> \", out_word)\n",
    "in_text = 'officials say '\n",
    "out_word = complete_pred1(in_text)\n",
    "print(\"Input text -->\", in_text, \"; predicted output ---> \", out_word)\n",
    "in_text = 'and sentenced '\n",
    "out_word = complete_pred1(in_text)\n",
    "print(\"Input text -->\", in_text, \"; predicted output ---> \", out_word)\n",
    "in_text = 'a combination '\n",
    "out_word = complete_pred1(in_text)\n",
    "print(\"Input text -->\", in_text, \"; predicted output ---> \", out_word)\n",
    "in_text = 'and according '\n",
    "out_word = complete_pred1(in_text)\n",
    "print(\"Input text -->\", in_text, \"; predicted output ---> \", out_word)\n",
    "in_text = 'department of '\n",
    "out_word = complete_pred1(in_text)\n",
    "print(\"Input text -->\", in_text, \"; predicted output ---> \", out_word)\n",
    "in_text = 'democrats and '\n",
    "out_word = complete_pred1(in_text)\n",
    "print(\"Input text -->\", in_text, \"; predicted output ---> \", out_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few more predictions and Comparions with Standard RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:40:22.203671Z",
     "start_time": "2025-01-21T03:40:20.996948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text --> how dangerous  \n",
      "LSTM Prediction --->  it \n",
      "RNN Prediction --->  of \n",
      "\n",
      "\n",
      "Input text --> political and  \n",
      "LSTM Prediction --->  economic \n",
      "RNN Prediction --->  the \n",
      "\n",
      "\n",
      "Input text --> of particular  \n",
      "LSTM Prediction --->  interest \n",
      "RNN Prediction --->  the \n",
      "\n",
      "\n",
      "Input text --> whatever they  \n",
      "LSTM Prediction --->  was \n",
      "RNN Prediction --->  the \n"
     ]
    }
   ],
   "source": [
    "in_text = 'how dangerous '\n",
    "out_word = complete_pred1(in_text)\n",
    "print(\"Input text -->\", in_text, \"\\nLSTM Prediction ---> \", out_word)\n",
    "out_word1 = complete_pred(in_text)\n",
    "print(\"RNN Prediction ---> \", out_word1)\n",
    "\n",
    "print(\"\\n\")\n",
    "in_text = 'political and '\n",
    "out_word = complete_pred1(in_text)\n",
    "print(\"Input text -->\", in_text, \"\\nLSTM Prediction ---> \", out_word)\n",
    "out_word1 = complete_pred(in_text)\n",
    "print(\"RNN Prediction ---> \", out_word1)\n",
    "\n",
    "print(\"\\n\")\n",
    "in_text = 'of particular '\n",
    "out_word = complete_pred1(in_text)\n",
    "print(\"Input text -->\", in_text, \"\\nLSTM Prediction ---> \", out_word)\n",
    "out_word1 = complete_pred(in_text)\n",
    "print(\"RNN Prediction ---> \", out_word1)\n",
    "\n",
    "print(\"\\n\")\n",
    "in_text = 'whatever they '\n",
    "out_word = complete_pred1(in_text)\n",
    "print(\"Input text -->\", in_text, \"\\nLSTM Prediction ---> \", out_word)\n",
    "out_word1 = complete_pred(in_text)\n",
    "print(\"RNN Prediction ---> \", out_word1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study – Language Translation Project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:40:35.869766Z",
     "start_time": "2025-01-21T03:40:35.256880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Go.' 'Va !'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)']\n",
      " ['Hi.' 'Salut !'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)']\n",
      " ['Hi.' 'Salut.'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)']\n",
      " ...\n",
      " [\"Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\"\n",
      "  \"La mort est une chose qu'on nous décourage souvent de discuter ou même de penser mais j'ai pris conscience que se préparer à la mort est l'une des choses que nous puissions faire qui nous investit le plus de responsabilité. Réfléchir à la mort clarifie notre vie.\"\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #1969962 (sacredceltic)']\n",
      " ['Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.'\n",
      "  \"Puisqu'il y a de multiples sites web sur chaque sujet, je clique d'habitude sur le bouton retour arrière lorsque j'atterris sur n'importe quelle page qui contient des publicités surgissantes. Je me rends juste sur la prochaine page proposée par Google et espère tomber sur quelque chose de moins irritant.\"\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #957693 (sacredceltic)']\n",
      " [\"If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\"\n",
      "  \"Si quelqu'un qui ne connaît pas vos antécédents dit que vous parlez comme un locuteur natif, cela veut dire qu'il a probablement remarqué quelque chose à propos de votre élocution qui lui a fait prendre conscience que vous n'êtes pas un locuteur natif. En d'autres termes, vous ne parlez pas vraiment comme un locuteur natif.\"\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #955961 (sacredceltic)']]\n",
      "Overall pairs 175623\n"
     ]
    }
   ],
   "source": [
    "raw_data= open(Data_path+\"/fra-eng/fra.txt\", mode='rt', encoding='utf-8').read()\n",
    "raw_data=raw_data.strip().split('\\n')\n",
    "raw_data=[i.split('\\t') for i in raw_data]\n",
    "lang1_lang2_data=array(raw_data)\n",
    "print(lang1_lang2_data)\n",
    "print(\"Overall pairs\", len(lang1_lang2_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:40:39.864503Z",
     "start_time": "2025-01-21T03:40:38.649460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Go' 'Va '\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)']\n",
      " ['Hi' 'Salut '\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)']\n",
      " ['Hi' 'Salut'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)']\n",
      " ...\n",
      " ['Death is something that were often discouraged to talk about or even think about but Ive realized that preparing for death is one of the most empowering things you can do Thinking about death clarifies your life'\n",
      "  'La mort est une chose quon nous décourage souvent de discuter ou même de penser mais jai pris conscience que se préparer à la mort est lune des choses que nous puissions faire qui nous investit le plus de responsabilité Réfléchir à la mort clarifie notre vie'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #1969962 (sacredceltic)']\n",
      " ['Since there are usually multiple websites on any given topic I usually just click the back button when I arrive on any webpage that has popup advertising I just go to the next page found by Google and hope for something less irritating'\n",
      "  'Puisquil y a de multiples sites web sur chaque sujet je clique dhabitude sur le bouton retour arrière lorsque jatterris sur nimporte quelle page qui contient des publicités surgissantes Je me rends juste sur la prochaine page proposée par Google et espère tomber sur quelque chose de moins irritant'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #957693 (sacredceltic)']\n",
      " ['If someone who doesnt know your background says that you sound like a native speaker it means they probably noticed something about your speaking that made them realize you werent a native speaker In other words you dont really sound like a native speaker'\n",
      "  'Si quelquun qui ne connaît pas vos antécédents dit que vous parlez comme un locuteur natif cela veut dire quil a probablement remarqué quelque chose à propos de votre élocution qui lui a fait prendre conscience que vous nêtes pas un locuteur natif En dautres termes vous ne parlez pas vraiment comme un locuteur natif'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #955961 (sacredceltic)']]\n"
     ]
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "lang1_lang2_data[:,0] = [word.translate(str.maketrans('', '', string.punctuation)) for word in lang1_lang2_data[:,0]]\n",
    "lang1_lang2_data[:,1] = [word.translate(str.maketrans('', '', string.punctuation)) for word in lang1_lang2_data[:,1]]\n",
    "\n",
    "print(lang1_lang2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:40:40.326289Z",
     "start_time": "2025-01-21T03:40:39.865809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go' 'va '\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)']\n",
      " ['hi' 'salut '\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)']\n",
      " ['hi' 'salut'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)']\n",
      " ...\n",
      " ['death is something that were often discouraged to talk about or even think about but ive realized that preparing for death is one of the most empowering things you can do thinking about death clarifies your life'\n",
      "  'la mort est une chose quon nous décourage souvent de discuter ou même de penser mais jai pris conscience que se préparer à la mort est lune des choses que nous puissions faire qui nous investit le plus de responsabilité réfléchir à la mort clarifie notre vie'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #1969962 (sacredceltic)']\n",
      " ['since there are usually multiple websites on any given topic i usually just click the back button when i arrive on any webpage that has popup advertising i just go to the next page found by google and hope for something less irritating'\n",
      "  'puisquil y a de multiples sites web sur chaque sujet je clique dhabitude sur le bouton retour arrière lorsque jatterris sur nimporte quelle page qui contient des publicités surgissantes je me rends juste sur la prochaine page proposée par google et espère tomber sur quelque chose de moins irritant'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #957693 (sacredceltic)']\n",
      " ['if someone who doesnt know your background says that you sound like a native speaker it means they probably noticed something about your speaking that made them realize you werent a native speaker in other words you dont really sound like a native speaker'\n",
      "  'si quelquun qui ne connaît pas vos antécédents dit que vous parlez comme un locuteur natif cela veut dire quil a probablement remarqué quelque chose à propos de votre élocution qui lui a fait prendre conscience que vous nêtes pas un locuteur natif en dautres termes vous ne parlez pas vraiment comme un locuteur natif'\n",
      "  'CC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #955961 (sacredceltic)']]\n"
     ]
    }
   ],
   "source": [
    "## convert text to lowercase\n",
    "for word in range(len(lang1_lang2_data)):\n",
    "    lang1_lang2_data[word,0] = lang1_lang2_data[word,0].lower()\n",
    "    lang1_lang2_data[word,1] = lang1_lang2_data[word,1].lower()\n",
    "print(lang1_lang2_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:40:41.591593Z",
     "start_time": "2025-01-21T03:40:40.327251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang1_vocab_size 14671\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lang1_lang2_data[:, 0])\n",
    "lang1_tokens=tokenizer\n",
    "lang1_vocab_size = len(lang1_tokens.word_index) + 1\n",
    "print(\"lang1_vocab_size\", lang1_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:40:43.087388Z",
     "start_time": "2025-01-21T03:40:41.592912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang2_vocab_size 33321\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lang1_lang2_data[:, 1])\n",
    "lang2_tokens=tokenizer\n",
    "lang2_vocab_size = len(lang2_tokens.word_index) + 1\n",
    "print(\"lang2_vocab_size\", lang2_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:40:43.285079Z",
     "start_time": "2025-01-21T03:40:43.088359Z"
    }
   },
   "outputs": [],
   "source": [
    "# split data into train and test set\n",
    "train, test = train_test_split(lang1_lang2_data, test_size=0.1, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:40:46.420030Z",
     "start_time": "2025-01-21T03:40:43.286450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (158060, 15)\n",
      "Y_train.shape (158060, 15)\n",
      "X_test.shape (17563, 15)\n",
      "Y_test.shape (17563, 15)\n"
     ]
    }
   ],
   "source": [
    "lang1_seq_length=15\n",
    "lang2_seq_length=15\n",
    "\n",
    "X_train_seq=lang1_tokens.texts_to_sequences(train[:, 0])\n",
    "X_train= pad_sequences(X_train_seq,lang1_seq_length,padding='post')\n",
    "\n",
    "Y_train_seq=lang2_tokens.texts_to_sequences(train[:, 1])\n",
    "Y_train= pad_sequences(Y_train_seq,lang2_seq_length,padding='post')\n",
    "\n",
    "X_test_seq=lang1_tokens.texts_to_sequences(test[:, 0])\n",
    "X_test= pad_sequences(X_test_seq,lang1_seq_length,padding='post')\n",
    "\n",
    "Y_test_seq=lang2_tokens.texts_to_sequences(test[:, 1])\n",
    "Y_test= pad_sequences(Y_test_seq,lang2_seq_length,padding='post')\n",
    "\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"Y_train.shape\",Y_train.shape)\n",
    "print(\"X_test.shape\",X_test.shape)\n",
    "print(\"Y_test.shape\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:40:46.424975Z",
     "start_time": "2025-01-21T03:40:46.421643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text data ['i had been studying music in boston before i returned to japan']\n",
      "Numbers sequence [1, 60, 91, 641, 451, 14, 236, 156, 1, 1285, 3, 476]\n",
      "Padded Sequence [   1   60   91  641  451   14  236  156    1 1285    3  476    0    0\n",
      "    0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Text data\", [train[5, 0]])\n",
    "print('Numbers sequence', X_train_seq[5])\n",
    "print('Padded Sequence', X_train[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:40:47.036251Z",
     "start_time": "2025-01-21T03:40:46.427486Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudarsun/venv/da5401/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(lang1_vocab_size, 256, input_length=lang1_seq_length, mask_zero=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(RepeatVector(lang2_seq_length))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dense(lang2_vocab_size, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T05:09:31.006485Z",
     "start_time": "2025-01-21T05:04:57.831000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m 231/1235\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:20\u001b[0m 200ms/step - loss: 5.8261"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEng_fra_model-e10.weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/venv/da5401/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/venv/da5401/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/venv/da5401/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/venv/da5401/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/venv/da5401/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/venv/da5401/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/da5401/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/venv/da5401/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/venv/da5401/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/venv/da5401/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m~/venv/da5401/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "history = model.fit(X_train, Y_train.reshape(Y_train.shape[0], Y_train.shape[1], 1),  epochs=10, verbose=1, batch_size=128)\n",
    "model.save_weights('Eng_fra_model-e10.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:41:09.588143Z",
     "start_time": "2025-01-21T03:41:09.533217Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"./Pre_trained_models/Eng_fra_model.hdf5\")\n",
    "#model.load_weights(\"Eng_fra_model-e10.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_line_prediction(text1, m):\n",
    "    #Given below is the code for pre-processing.\n",
    "    def to_lines(text):\n",
    "        sents = text.strip().split('\\n')\n",
    "        sents = [i.split('\\t') for i in sents]\n",
    "        return sents\n",
    "\n",
    "    small_input = to_lines(text1)\n",
    "    small_input = np.array(small_input)\n",
    "\n",
    "    # Remove punctuation\n",
    "    small_input[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in small_input[:,0]]\n",
    "    # convert text to lowercase\n",
    "    for i in range(len(small_input)):\n",
    "        small_input[i,0] = small_input[i,0].lower()\n",
    "\n",
    "    #encode and pad sequences\n",
    "    small_input_seq=lang1_tokens.texts_to_sequences(small_input[0])\n",
    "    small_input= keras.utils.pad_sequences(small_input_seq,15,padding='post')\n",
    "\n",
    "    pred_seq = m.predict(small_input[0:1].reshape((small_input[0:1].shape[0],small_input[0:1].shape[1])), verbose=0)\n",
    "    #print(pred_seq.shape)\n",
    "    #print(pred_seq)\n",
    "\n",
    "    pred1 = [np.argmax(i) for i in pred_seq[0]]\n",
    "    #print(pred1)\n",
    "\n",
    "    def num_to_word(n, tokens):\n",
    "        for word, index in tokens.word_index.items():\n",
    "            if index == n:\n",
    "                return word\n",
    "        return None\n",
    "\n",
    "    Lang2_text = []\n",
    "    for wid in pred1:\n",
    "        t = num_to_word(wid, lang2_tokens)\n",
    "        if t != None:\n",
    "            Lang2_text.append(t)\n",
    "\n",
    "    return(' '.join(Lang2_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T06:38:16.735276Z",
     "start_time": "2025-01-21T06:35:08.583495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['have a great Good day']  --> une une bonne journée\n",
      "['Do you speak English']  --> parlezvous langlais \n",
      "['I do not know your language']  --> je ne connais pas votre ville\n",
      "['I need help']  --> jai besoin de daide\n",
      "['Thank you very much']  --> merci beaucoup\n",
      "['Where can I get this']  --> où puisje faire\n",
      "['How much does it cost']  --> combien combien ça coûte \n",
      "['Where is the bathroom']  --> où est la toilettes de\n",
      "['Where is the ATM']  --> où est trouve la\n",
      "['I am a visitor here']  --> je suis ici ici\n",
      "['Excuse me']  --> excusezmoi\n",
      "['I need love']  --> jai besoin de\n",
      "['What do you do for living']  --> que que à\n",
      "['Here is my passport']  --> voici mon passeport\n"
     ]
    }
   ],
   "source": [
    "Input_sentences=[\"have a great Good day\",\n",
    "                 \"Do you speak English\",\n",
    "                 \"I do not know your language\",\n",
    "                 \"I need help\",\n",
    "                 \"Thank you very much\",\n",
    "                 \"Where can I get this\",\n",
    "                 \"How much does it cost\",\n",
    "                 \"Where is the bathroom\",\n",
    "                 \"Where is the ATM\",\n",
    "                 \"I am a visitor here\",\n",
    "                 \"Excuse me\",\n",
    "                 \"I need love\",\n",
    "                 \"What do you do for living\",\n",
    "                 \"Here is my passport\"]\n",
    "\n",
    "for sent in Input_sentences:\n",
    "  print([sent] , \" -->\",one_line_prediction(sent, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da5401",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
