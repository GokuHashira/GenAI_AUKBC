{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9kb1waqT2mV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Activation, LSTM, RepeatVector, Input\n",
        "#from google.colab import drive\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3vjs1-tfzYo",
        "outputId": "a5ea662c-b774-4d31-933d-82d18c8d77ab"
      },
      "outputs": [],
      "source": [
        "# download the data set\n",
        "gdown.download(url=\"https://drive.google.com/file/d/16h_8WHOp2mFCyIqbjNIZ5omayG-P42wU/view?usp=sharing\", output=\"fra.txt\", fuzzy=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsIFB-VVT2mW",
        "outputId": "a5abd958-d911-4f44-acb7-5022103c4521"
      },
      "outputs": [],
      "source": [
        "raw_data = open(r\"./fra.txt\", mode='rt', encoding='utf-8').read()\n",
        "raw_data = raw_data.strip().split(\"\\n\")\n",
        "raw_data = [i.split('\\t') for i in raw_data]\n",
        "data = np.array(raw_data)\n",
        "print(data)\n",
        "print(\"overall pairs\", len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbMqa5l9T2mW",
        "outputId": "f747816e-7110-478f-c6e8-2fdbc64b7d30"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i04o5pTT2mX"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-o4VwcPT2mX"
      },
      "outputs": [],
      "source": [
        "data[:,0] = [word.translate(str.maketrans('', '', string.punctuation)) for word in data[:,0]]\n",
        "data[:,1] = [word.translate(str.maketrans('', '', string.punctuation)) for word in data[:,1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oL2LZw7zT2mX"
      },
      "outputs": [],
      "source": [
        "for word in range(len(data)):\n",
        "    data[word,0] = data[word,0].lower()\n",
        "    data[word,1] = data[word,1].lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs3Ju9X8T2mX",
        "outputId": "752b9798-b9d3-4b29-8e4d-ee2e1e63fedc"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data[:,0])\n",
        "l1_tokens = tokenizer\n",
        "l1_vocab_size = len(l1_tokens.word_index) + 1\n",
        "print(\"lang 1 vocab size\", l1_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD0GsloST2mY",
        "outputId": "845b0bcf-60c5-4752-d919-b0ce81a9cc64"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data[:,1])\n",
        "l2_tokens = tokenizer\n",
        "l2_vocab_size = len(l2_tokens.word_index) + 1\n",
        "print(\"lang 2 vocab size\", l2_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrN5T8AiT2mY",
        "outputId": "e38241d5-4fa6-43db-ce47-4d3c0fa1dcb9"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(data, test_size=0.1, random_state=43)\n",
        "X_train_seq = l1_tokens.texts_to_sequences(train[:,0])\n",
        "X_train = keras.utils.pad_sequences(X_train_seq, 15, padding='post')\n",
        "Y_train_seq = l2_tokens.texts_to_sequences(train[:,1])\n",
        "Y_train = keras.utils.pad_sequences(Y_train_seq, 15, padding='post')\n",
        "\n",
        "X_test_seq = l1_tokens.texts_to_sequences(test[:,0])\n",
        "X_test = keras.utils.pad_sequences(X_test_seq, 15, padding='post')\n",
        "Y_test_seq = l2_tokens.texts_to_sequences(test[:,1])\n",
        "Y_test = keras.utils.pad_sequences(Y_test_seq, 15, padding='post')\n",
        "\n",
        "print(\"X_train.shape\", X_train.shape)\n",
        "print(\"Y_train.shape\", Y_train.shape)\n",
        "print(\"X_test.shape\", X_test.shape)\n",
        "print(\"Y_test.shape\", Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77IskGPUT2mY",
        "outputId": "b4da4b60-00f1-409b-9cc8-58504c12f63e"
      },
      "outputs": [],
      "source": [
        "print(\"text data -->\", train[15, 1])\n",
        "print(\"numbers sequence -->\", Y_train_seq[15])\n",
        "print(\"padded sequence --->\", Y_train[15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "4L8YWkdjT2mY",
        "outputId": "23dd502e-431d-4442-8683-1bff4e97d2c3"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(15,), name='input'))\n",
        "model.add(Embedding(l1_vocab_size, 256, input_length = 15, mask_zero=True, name='embedding'))\n",
        "model.add(LSTM(128, name='encoder'))\n",
        "model.add(RepeatVector(15))\n",
        "model.add(LSTM(128, return_sequences=True, name='decoder'))\n",
        "model.add(Dense(l2_vocab_size, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "n-ahYs15T2mZ",
        "outputId": "2ae72bd2-1321-4157-c385-9485b26ac1c1"
      },
      "outputs": [],
      "source": [
        "\n",
        "history = model.fit(X_train, Y_train.reshape(Y_train.shape[0], Y_train.shape[1], 1), epochs=10, verbose=1, batch_size=256)\n",
        "model.save_weights('my_eng_fra_model_e10.weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf1A9BxOT2mZ"
      },
      "outputs": [],
      "source": [
        "def one_line_prediction(text1, m):\n",
        "    #Given below is the code for pre-processing.\n",
        "    def to_lines(text):\n",
        "        sents = text.strip().split('\\n')\n",
        "        sents = [i.split('\\t') for i in sents]\n",
        "        return sents\n",
        "\n",
        "    small_input = to_lines(text1)\n",
        "    small_input = np.array(small_input)\n",
        "\n",
        "    # Remove punctuation\n",
        "    small_input[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in small_input[:,0]]\n",
        "    # convert text to lowercase\n",
        "    for i in range(len(small_input)):\n",
        "        small_input[i,0] = small_input[i,0].lower()\n",
        "\n",
        "    #encode and pad sequences\n",
        "    small_input_seq=l1_tokens.texts_to_sequences(small_input[0])\n",
        "    small_input= keras.utils.pad_sequences(small_input_seq,15,padding='post')\n",
        "\n",
        "\n",
        "    #Using the code below, we load the model and get the prediction sequence.\n",
        "    #model.load_weights('/content/drive/My Drive/Training/Book/0.Chapters/Chapter12 RNN and LSTM/1.Archives/Eng_fra_model_v2.hdf5')\n",
        "\n",
        "    pred_seq = m.predict(small_input[0:1].reshape((small_input[0:1].shape[0],small_input[0:1].shape[1])), verbose=0)\n",
        "    print(pred_seq.shape)\n",
        "    #print(pred_seq)\n",
        "\n",
        "    pred1 = [np.argmax(i) for i in pred_seq[0]]\n",
        "    print(pred1)\n",
        "\n",
        "    def num_to_word(n, tokens):\n",
        "        for word, index in tokens.word_index.items():\n",
        "            if index == n:\n",
        "                return word\n",
        "        return None\n",
        "\n",
        "    Lang2_text = []\n",
        "    for wid in pred1:\n",
        "        t = num_to_word(wid, l2_tokens)\n",
        "        if t != None:\n",
        "            Lang2_text.append(t)\n",
        "\n",
        "    return(' '.join(Lang2_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-8JYtqDT2ma",
        "outputId": "c0696c86-a25f-480f-d0fd-c0008b00412e"
      },
      "outputs": [],
      "source": [
        "one_line_prediction(\"what is the breakfast today?\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrGnkYANT2ma",
        "outputId": "0afcf987-e062-41d9-b7f7-fae8b7600f46"
      },
      "outputs": [],
      "source": [
        "m2 = Sequential()\n",
        "m2.add(Input(shape=(15,)))\n",
        "m2.add(Embedding(l1_vocab_size, 256, input_length = 15, mask_zero=True))\n",
        "m2.add(LSTM(128))\n",
        "m2.add(RepeatVector(15))\n",
        "m2.add(LSTM(128, return_sequences=True))\n",
        "m2.add(Dense(l2_vocab_size, activation='softmax'))\n",
        "m2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUSHi5UcT2ma"
      },
      "outputs": [],
      "source": [
        "# download the pretrained model.\n",
        "gdown.download(url='https://drive.google.com/file/d/1_cO3qEeI2GMkToD7DEVXmjirDVwiPDSU/view?usp=sharing', output='Eng_fra_model.hdf5', fuzzy=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the model weights.\n",
        "m2.load_weights('Eng_fra_model.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "AyOH1Ua2T2ma",
        "outputId": "9cbc9bb1-f4d9-4c53-d5af-36f3d5f3c0c9"
      },
      "outputs": [],
      "source": [
        "one_line_prediction(\"i am beautiful\", m2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf0zAcUQT2ma"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "da5401",
      "language": "python",
      "name": "da5401"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
