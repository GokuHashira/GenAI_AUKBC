{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i9kb1waqT2mV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Activation, LSTM, RepeatVector\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3vjs1-tfzYo",
        "outputId": "a5ea662c-b774-4d31-933d-82d18c8d77ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gsIFB-VVT2mW",
        "outputId": "a5abd958-d911-4f44-acb7-5022103c4521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Go.' 'Va !'\n",
            "  'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)']\n",
            " ['Hi.' 'Salut !'\n",
            "  'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)']\n",
            " ['Hi.' 'Salut.'\n",
            "  'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)']\n",
            " ...\n",
            " [\"Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\"\n",
            "  \"La mort est une chose qu'on nous décourage souvent de discuter ou même de penser mais j'ai pris conscience que se préparer à la mort est l'une des choses que nous puissions faire qui nous investit le plus de responsabilité. Réfléchir à la mort clarifie notre vie.\"\n",
            "  'CC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #1969962 (sacredceltic)']\n",
            " ['Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.'\n",
            "  \"Puisqu'il y a de multiples sites web sur chaque sujet, je clique d'habitude sur le bouton retour arrière lorsque j'atterris sur n'importe quelle page qui contient des publicités surgissantes. Je me rends juste sur la prochaine page proposée par Google et espère tomber sur quelque chose de moins irritant.\"\n",
            "  'CC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #957693 (sacredceltic)']\n",
            " [\"If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\"\n",
            "  \"Si quelqu'un qui ne connaît pas vos antécédents dit que vous parlez comme un locuteur natif, cela veut dire qu'il a probablement remarqué quelque chose à propos de votre élocution qui lui a fait prendre conscience que vous n'êtes pas un locuteur natif. En d'autres termes, vous ne parlez pas vraiment comme un locuteur natif.\"\n",
            "  'CC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #955961 (sacredceltic)']]\n",
            "overall pairs 175623\n"
          ]
        }
      ],
      "source": [
        "raw_data = open(r\"/content/drive/MyDrive/ML_DL_py_TF/fra.txt\", mode='rt', encoding='utf-8').read()\n",
        "raw_data = raw_data.strip().split(\"\\n\")\n",
        "raw_data = [i.split('\\t') for i in raw_data]\n",
        "data = np.array(raw_data)\n",
        "print(data)\n",
        "print(\"overall pairs\", len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CbMqa5l9T2mW",
        "outputId": "f747816e-7110-478f-c6e8-2fdbc64b7d30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(175623, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3i04o5pTT2mX"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3-o4VwcPT2mX"
      },
      "outputs": [],
      "source": [
        "data[:,0] = [word.translate(str.maketrans('', '', string.punctuation)) for word in data[:,0]]\n",
        "data[:,1] = [word.translate(str.maketrans('', '', string.punctuation)) for word in data[:,1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oL2LZw7zT2mX"
      },
      "outputs": [],
      "source": [
        "for word in range(len(data)):\n",
        "    data[word,0] = data[word,0].lower()\n",
        "    data[word,1] = data[word,1].lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gs3Ju9X8T2mX",
        "outputId": "752b9798-b9d3-4b29-8e4d-ee2e1e63fedc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lang 1 vocab size 14671\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data[:,0])\n",
        "l1_tokens = tokenizer\n",
        "l1_vocab_size = len(l1_tokens.word_index) + 1\n",
        "print(\"lang 1 vocab size\", l1_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pD0GsloST2mY",
        "outputId": "845b0bcf-60c5-4752-d919-b0ce81a9cc64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lang 2 vocab size 33321\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data[:,1])\n",
        "l2_tokens = tokenizer\n",
        "l2_vocab_size = len(l2_tokens.word_index) + 1\n",
        "print(\"lang 2 vocab size\", l2_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vrN5T8AiT2mY",
        "outputId": "e38241d5-4fa6-43db-ce47-4d3c0fa1dcb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape (158060, 15)\n",
            "Y_train.shape (158060, 15)\n",
            "X_test.shape (17563, 15)\n",
            "Y_test.shape (17563, 15)\n"
          ]
        }
      ],
      "source": [
        "train, test = train_test_split(data, test_size=0.1, random_state=43)\n",
        "X_train_seq = l1_tokens.texts_to_sequences(train[:,0])\n",
        "X_train = keras.utils.pad_sequences(X_train_seq, 15, padding='post')\n",
        "Y_train_seq = l2_tokens.texts_to_sequences(train[:,1])\n",
        "Y_train = keras.utils.pad_sequences(Y_train_seq, 15, padding='post')\n",
        "\n",
        "X_test_seq = l1_tokens.texts_to_sequences(test[:,0])\n",
        "X_test = keras.utils.pad_sequences(X_test_seq, 15, padding='post')\n",
        "Y_test_seq = l2_tokens.texts_to_sequences(test[:,1])\n",
        "Y_test = keras.utils.pad_sequences(Y_test_seq, 15, padding='post')\n",
        "\n",
        "print(\"X_train.shape\", X_train.shape)\n",
        "print(\"Y_train.shape\", Y_train.shape)\n",
        "print(\"X_test.shape\", X_test.shape)\n",
        "print(\"Y_test.shape\", Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "77IskGPUT2mY",
        "outputId": "b4da4b60-00f1-409b-9cc8-58504c12f63e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text data --> je ne pense pas que tom écoute\n",
            "numbers sequence --> [1, 6, 58, 3, 4, 11, 1747]\n",
            "padded sequence ---> [   1    6   58    3    4   11 1747    0    0    0    0    0    0    0\n",
            "    0]\n"
          ]
        }
      ],
      "source": [
        "print(\"text data -->\", train[15, 1])\n",
        "print(\"numbers sequence -->\", Y_train_seq[15])\n",
        "print(\"padded sequence --->\", Y_train[15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4L8YWkdjT2mY",
        "outputId": "23dd502e-431d-4442-8683-1bff4e97d2c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(l1_vocab_size, 256, input_length = 15, mask_zero=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(RepeatVector(15))\n",
        "model.add(LSTM(128, return_sequences=True))\n",
        "model.add(Dense(l2_vocab_size, activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n-ahYs15T2mZ",
        "outputId": "2ae72bd2-1321-4157-c385-9485b26ac1c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6387f7353966>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m history = model.fit(X_train, Y_train.reshape(Y_train.shape[0], Y_train.shape[1], 1), \n\u001b[1;32m      3\u001b[0m                     epochs=30, verbose=1, batch_size=1024)\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eng_fra_model.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "history = model.fit(X_train, Y_train.reshape(Y_train.shape[0], Y_train.shape[1], 1),\n",
        "                    epochs=30, verbose=1, batch_size=1024)\n",
        "model.save_weights('eng_fra_model.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf1A9BxOT2mZ"
      },
      "outputs": [],
      "source": [
        "def one_line_prediction(text1, m):\n",
        "    #Given below is the code for pre-processing.\n",
        "    def to_lines(text):\n",
        "        sents = text.strip().split('\\n')\n",
        "        sents = [i.split('\\t') for i in sents]\n",
        "        return sents\n",
        "\n",
        "    small_input = to_lines(text1)\n",
        "    small_input = np.array(small_input)\n",
        "\n",
        "    # Remove punctuation\n",
        "    small_input[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in small_input[:,0]]\n",
        "    # convert text to lowercase\n",
        "    for i in range(len(small_input)):\n",
        "        small_input[i,0] = small_input[i,0].lower()\n",
        "\n",
        "    #encode and pad sequences\n",
        "    small_input_seq=l1_tokens.texts_to_sequences(small_input[0])\n",
        "    small_input= keras.utils.pad_sequences(small_input_seq,15,padding='post')\n",
        "\n",
        "\n",
        "    #Using the code below, we load the model and get the prediction sequence.\n",
        "    #model.load_weights('/content/drive/My Drive/Training/Book/0.Chapters/Chapter12 RNN and LSTM/1.Archives/Eng_fra_model_v2.hdf5')\n",
        "\n",
        "    pred_seq = m.predict(small_input[0:1].reshape((small_input[0:1].shape[0],small_input[0:1].shape[1])), verbose=0)\n",
        "    print(pred_seq.shape)\n",
        "    #print(pred_seq)\n",
        "\n",
        "    pred1 = [np.argmax(i) for i in pred_seq[0]]\n",
        "    print(pred1)\n",
        "\n",
        "    def num_to_word(n, tokens):\n",
        "        for word, index in tokens.word_index.items():\n",
        "            if index == n:\n",
        "                return word\n",
        "        return None\n",
        "\n",
        "    Lang2_text = []\n",
        "    for wid in pred1:\n",
        "        t = num_to_word(wid, l2_tokens)\n",
        "        if t != None:\n",
        "            Lang2_text.append(t)\n",
        "\n",
        "    return(' '.join(Lang2_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-8JYtqDT2ma",
        "outputId": "c0696c86-a25f-480f-d0fd-c0008b00412e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 15, 33321)\n",
            "[9, 9, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'vous vous avec'"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "one_line_prediction(\"are you ok baby\", model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrGnkYANT2ma",
        "outputId": "0afcf987-e062-41d9-b7f7-fae8b7600f46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 15, 256)           3755776   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 128)               197120    \n",
            "                                                                 \n",
            " repeat_vector_1 (RepeatVect  (None, 15, 128)          0         \n",
            " or)                                                             \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 15, 128)           131584    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 15, 33321)         4298409   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,382,889\n",
            "Trainable params: 8,382,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "m2 = Sequential()\n",
        "m2.add(Embedding(l1_vocab_size, 256, input_length = 15, mask_zero=True))\n",
        "m2.add(LSTM(128))\n",
        "m2.add(RepeatVector(15))\n",
        "m2.add(LSTM(128, return_sequences=True))\n",
        "m2.add(Dense(l2_vocab_size, activation='softmax'))\n",
        "m2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUSHi5UcT2ma"
      },
      "outputs": [],
      "source": [
        "m2.load_weights(r'/content/drive/MyDrive/ML_DL_py_TF/Eng_fra_model.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyOH1Ua2T2ma",
        "outputId": "9cbc9bb1-f4d9-4c53-d5af-36f3d5f3c0c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 15, 33321)\n",
            "[78, 4, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'estce que tu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "one_line_prediction(\"are you ok baby\", m2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf0zAcUQT2ma"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}