{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOdy6lmqynlU"
      },
      "source": [
        "# Sequence to sequence learning for performing number addition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwfFpDh5ynlW"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this example, we train a model to learn to add two numbers, provided as strings.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "- Input: \"535+61\"\n",
        "- Output: \"596\"\n",
        "\n",
        "Input may optionally be reversed, which was shown to increase performance in many tasks\n",
        " in: [Learning to Execute](http://arxiv.org/abs/1410.4615) and\n",
        "[Sequence to Sequence Learning with Neural Networks](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf).\n",
        "\n",
        "Theoretically, sequence order inversion introduces shorter term dependencies between\n",
        " source and target for this problem.\n",
        "\n",
        "**Results:**\n",
        "\n",
        "For two digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
        "\n",
        "Three digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
        "\n",
        "Four digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
        "\n",
        "Five digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eEU_T2xynlW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l3AKyQmdynlX"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# Parameters for the model and dataset.\n",
        "TRAINING_SIZE = 50000\n",
        "DIGITS = 3\n",
        "REVERSE = True\n",
        "\n",
        "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
        "# int is DIGITS.\n",
        "MAXLEN = DIGITS + 1 + DIGITS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-RL-xYBynlX"
      },
      "source": [
        "## Generate the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m7WlcsgJynlY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f02c67c5-64bf-4ec9-9d54-c185541abf5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating data...\n",
            "Total questions: 50000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class CharacterTable:\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one-hot integer representation\n",
        "    + Decode the one-hot or integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One-hot encode given string C.\n",
        "        # Arguments\n",
        "            C: string, to be encoded.\n",
        "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        \"\"\"Decode the given vector or 2D array to their character output.\n",
        "        # Arguments\n",
        "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
        "                or a vector of character indices (used with `calc_argmax=False`).\n",
        "            calc_argmax: Whether to find the character index with maximum\n",
        "                probability, defaults to `True`.\n",
        "        \"\"\"\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return \"\".join(self.indices_char[x] for x in x)\n",
        "\n",
        "\n",
        "# All the numbers, plus sign and space for padding.\n",
        "chars = \"0123456789+ \"\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print(\"Generating data...\")\n",
        "while len(questions) < TRAINING_SIZE:\n",
        "    f = lambda: int(\n",
        "        \"\".join(\n",
        "            np.random.choice(list(\"0123456789\"))\n",
        "            for i in range(np.random.randint(1, DIGITS + 1))\n",
        "        )\n",
        "    )\n",
        "    a, b = f(), f()\n",
        "    # Skip any addition questions we've already seen\n",
        "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # Pad the data with spaces such that it is always MAXLEN.\n",
        "    q = \"{}+{}\".format(a, b)\n",
        "    query = q + \" \" * (MAXLEN - len(q))\n",
        "    ans = str(a + b)\n",
        "    # Answers can be of maximum size DIGITS + 1.\n",
        "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
        "    if REVERSE:\n",
        "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
        "        # space used for padding.)\n",
        "        query = query[::-1]\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "print(\"Total questions:\", len(questions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXraNnpfynlY"
      },
      "source": [
        "## Vectorize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZjKm0mwnynlY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19434c19-9c83-436f-be53-e01a7ecc08b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorization...\n",
            "Training Data:\n",
            "(45000, 7, 12)\n",
            "(45000, 4, 12)\n",
            "Validation Data:\n",
            "(5000, 7, 12)\n",
            "(5000, 4, 12)\n"
          ]
        }
      ],
      "source": [
        "print(\"Vectorization...\")\n",
        "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=bool)\n",
        "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, MAXLEN)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
        "\n",
        "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
        "# digits.\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Explicitly set apart 10% for validation data that we never train over.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "print(\"Training Data:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(\"Validation Data:\")\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwkw-MaSynlZ"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7Qi7mxROynlZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "c841fa80-c602-4eca-c9d2-1ffd38a25532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m72,192\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector (\u001b[38;5;33mRepeatVector\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m12\u001b[0m)          │         \u001b[38;5;34m1,548\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">72,192</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ repeat_vector (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,548</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m205,324\u001b[0m (802.05 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,324</span> (802.05 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m205,324\u001b[0m (802.05 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">205,324</span> (802.05 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"Build model...\")\n",
        "num_layers = 1  # Try to add more LSTM layers!\n",
        "\n",
        "model = keras.Sequential()\n",
        "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
        "# Note: In a situation where your input sequences have a variable length,\n",
        "# use input_shape=(None, num_feature).\n",
        "model.add(layers.Input((MAXLEN, len(chars))))\n",
        "model.add(layers.LSTM(128))\n",
        "# As the decoder RNN's input, repeatedly provide with the last output of\n",
        "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
        "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "# The decoder RNN could be multiple layers stacked or a single layer.\n",
        "for _ in range(num_layers):\n",
        "    # By setting return_sequences to True, return not only the last output but\n",
        "    # all the outputs so far in the form of (num_samples, timesteps,\n",
        "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
        "    # the first dimension to be the timesteps.\n",
        "    model.add(layers.LSTM(128, return_sequences=True))\n",
        "\n",
        "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
        "# of the output sequence, decide which character should be chosen.\n",
        "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEg7MARFynlZ"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H25En7O_ynlZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "354e6053-f4e1-4bce-9864-e277329b1af7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 1\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.3218 - loss: 1.8828 - val_accuracy: 0.4132 - val_loss: 1.5650\n",
            "Q 663+79  T 742  \u001b[91m☒ 700 \u001b[0m\n",
            "Q 30+250  T 280  \u001b[91m☒ 331 \u001b[0m\n",
            "Q 337+669 T 1006 \u001b[91m☒ 113 \u001b[0m\n",
            "Q 84+762  T 846  \u001b[91m☒ 801 \u001b[0m\n",
            "Q 589+36  T 625  \u001b[91m☒ 880 \u001b[0m\n",
            "Q 3+212   T 215  \u001b[91m☒ 333 \u001b[0m\n",
            "Q 674+1   T 675  \u001b[91m☒ 777 \u001b[0m\n",
            "Q 190+408 T 598  \u001b[91m☒ 480 \u001b[0m\n",
            "Q 438+437 T 875  \u001b[91m☒ 810 \u001b[0m\n",
            "Q 344+25  T 369  \u001b[91m☒ 457 \u001b[0m\n",
            "\n",
            "Iteration 2\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4556 - loss: 1.4575 - val_accuracy: 0.5360 - val_loss: 1.2187\n",
            "Q 64+449  T 513  \u001b[91m☒ 529 \u001b[0m\n",
            "Q 67+544  T 611  \u001b[91m☒ 619 \u001b[0m\n",
            "Q 126+5   T 131  \u001b[91m☒ 151 \u001b[0m\n",
            "Q 433+83  T 516  \u001b[91m☒ 509 \u001b[0m\n",
            "Q 975+10  T 985  \u001b[91m☒ 900 \u001b[0m\n",
            "Q 826+9   T 835  \u001b[91m☒ 859 \u001b[0m\n",
            "Q 38+26   T 64   \u001b[91m☒ 55  \u001b[0m\n",
            "Q 157+332 T 489  \u001b[91m☒ 529 \u001b[0m\n",
            "Q 18+362  T 380  \u001b[91m☒ 395 \u001b[0m\n",
            "Q 126+32  T 158  \u001b[91m☒ 161 \u001b[0m\n",
            "\n",
            "Iteration 3\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.5830 - loss: 1.1194 - val_accuracy: 0.6522 - val_loss: 0.9580\n",
            "Q 105+589 T 694  \u001b[91m☒ 799 \u001b[0m\n",
            "Q 775+6   T 781  \u001b[91m☒ 787 \u001b[0m\n",
            "Q 536+17  T 553  \u001b[91m☒ 549 \u001b[0m\n",
            "Q 337+574 T 911  \u001b[91m☒ 801 \u001b[0m\n",
            "Q 210+38  T 248  \u001b[92m☑ 248 \u001b[0m\n",
            "Q 35+129  T 164  \u001b[91m☒ 161 \u001b[0m\n",
            "Q 980+22  T 1002 \u001b[91m☒ 900 \u001b[0m\n",
            "Q 56+57   T 113  \u001b[91m☒ 107 \u001b[0m\n",
            "Q 19+331  T 350  \u001b[91m☒ 351 \u001b[0m\n",
            "Q 44+317  T 361  \u001b[91m☒ 351 \u001b[0m\n",
            "\n",
            "Iteration 4\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.6637 - loss: 0.9144 - val_accuracy: 0.7031 - val_loss: 0.8078\n",
            "Q 71+317  T 388  \u001b[91m☒ 481 \u001b[0m\n",
            "Q 439+500 T 939  \u001b[91m☒ 942 \u001b[0m\n",
            "Q 16+87   T 103  \u001b[91m☒ 102 \u001b[0m\n",
            "Q 0+623   T 623  \u001b[92m☑ 623 \u001b[0m\n",
            "Q 260+30  T 290  \u001b[91m☒ 291 \u001b[0m\n",
            "Q 159+5   T 164  \u001b[91m☒ 161 \u001b[0m\n",
            "Q 130+622 T 752  \u001b[91m☒ 750 \u001b[0m\n",
            "Q 1+771   T 772  \u001b[92m☑ 772 \u001b[0m\n",
            "Q 969+321 T 1290 \u001b[91m☒ 1398\u001b[0m\n",
            "Q 128+812 T 940  \u001b[91m☒ 942 \u001b[0m\n",
            "\n",
            "Iteration 5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.7133 - loss: 0.7864 - val_accuracy: 0.7436 - val_loss: 0.7097\n",
            "Q 533+77  T 610  \u001b[91m☒ 613 \u001b[0m\n",
            "Q 378+65  T 443  \u001b[91m☒ 442 \u001b[0m\n",
            "Q 940+72  T 1012 \u001b[91m☒ 1017\u001b[0m\n",
            "Q 207+8   T 215  \u001b[91m☒ 213 \u001b[0m\n",
            "Q 78+472  T 550  \u001b[91m☒ 547 \u001b[0m\n",
            "Q 934+850 T 1784 \u001b[91m☒ 1790\u001b[0m\n",
            "Q 911+911 T 1822 \u001b[91m☒ 1731\u001b[0m\n",
            "Q 421+16  T 437  \u001b[92m☑ 437 \u001b[0m\n",
            "Q 517+16  T 533  \u001b[91m☒ 530 \u001b[0m\n",
            "Q 881+93  T 974  \u001b[91m☒ 973 \u001b[0m\n",
            "\n",
            "Iteration 6\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.7469 - loss: 0.6951 - val_accuracy: 0.7529 - val_loss: 0.6728\n",
            "Q 945+34  T 979  \u001b[91m☒ 970 \u001b[0m\n",
            "Q 16+89   T 105  \u001b[91m☒ 103 \u001b[0m\n",
            "Q 56+874  T 930  \u001b[91m☒ 938 \u001b[0m\n",
            "Q 30+500  T 530  \u001b[91m☒ 523 \u001b[0m\n",
            "Q 703+4   T 707  \u001b[91m☒ 708 \u001b[0m\n",
            "Q 60+884  T 944  \u001b[91m☒ 948 \u001b[0m\n",
            "Q 5+464   T 469  \u001b[91m☒ 470 \u001b[0m\n",
            "Q 134+160 T 294  \u001b[91m☒ 298 \u001b[0m\n",
            "Q 54+54   T 108  \u001b[91m☒ 112 \u001b[0m\n",
            "Q 294+177 T 471  \u001b[91m☒ 462 \u001b[0m\n",
            "\n",
            "Iteration 7\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.7960 - loss: 0.5634 - val_accuracy: 0.8633 - val_loss: 0.3841\n",
            "Q 25+308  T 333  \u001b[91m☒ 332 \u001b[0m\n",
            "Q 638+34  T 672  \u001b[92m☑ 672 \u001b[0m\n",
            "Q 916+12  T 928  \u001b[92m☑ 928 \u001b[0m\n",
            "Q 514+860 T 1374 \u001b[92m☑ 1374\u001b[0m\n",
            "Q 77+77   T 154  \u001b[91m☒ 153 \u001b[0m\n",
            "Q 485+2   T 487  \u001b[92m☑ 487 \u001b[0m\n",
            "Q 83+513  T 596  \u001b[92m☑ 596 \u001b[0m\n",
            "Q 360+682 T 1042 \u001b[91m☒ 1032\u001b[0m\n",
            "Q 717+476 T 1193 \u001b[91m☒ 1194\u001b[0m\n",
            "Q 711+98  T 809  \u001b[92m☑ 809 \u001b[0m\n",
            "\n",
            "Iteration 8\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8955 - loss: 0.3227 - val_accuracy: 0.9517 - val_loss: 0.1950\n",
            "Q 3+231   T 234  \u001b[92m☑ 234 \u001b[0m\n",
            "Q 32+988  T 1020 \u001b[91m☒ 1021\u001b[0m\n",
            "Q 47+75   T 122  \u001b[92m☑ 122 \u001b[0m\n",
            "Q 759+681 T 1440 \u001b[92m☑ 1440\u001b[0m\n",
            "Q 785+83  T 868  \u001b[92m☑ 868 \u001b[0m\n",
            "Q 237+109 T 346  \u001b[92m☑ 346 \u001b[0m\n",
            "Q 832+945 T 1777 \u001b[92m☑ 1777\u001b[0m\n",
            "Q 27+504  T 531  \u001b[92m☑ 531 \u001b[0m\n",
            "Q 869+947 T 1816 \u001b[92m☑ 1816\u001b[0m\n",
            "Q 236+51  T 287  \u001b[92m☑ 287 \u001b[0m\n",
            "\n",
            "Iteration 9\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9499 - loss: 0.1885 - val_accuracy: 0.9726 - val_loss: 0.1233\n",
            "Q 91+22   T 113  \u001b[92m☑ 113 \u001b[0m\n",
            "Q 542+506 T 1048 \u001b[91m☒ 1058\u001b[0m\n",
            "Q 947+59  T 1006 \u001b[92m☑ 1006\u001b[0m\n",
            "Q 51+780  T 831  \u001b[92m☑ 831 \u001b[0m\n",
            "Q 862+506 T 1368 \u001b[92m☑ 1368\u001b[0m\n",
            "Q 530+723 T 1253 \u001b[92m☑ 1253\u001b[0m\n",
            "Q 405+93  T 498  \u001b[91m☒ 598 \u001b[0m\n",
            "Q 97+0    T 97   \u001b[92m☑ 97  \u001b[0m\n",
            "Q 671+89  T 760  \u001b[92m☑ 760 \u001b[0m\n",
            "Q 893+904 T 1797 \u001b[92m☑ 1797\u001b[0m\n",
            "\n",
            "Iteration 10\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9723 - loss: 0.1166 - val_accuracy: 0.9843 - val_loss: 0.0805\n",
            "Q 329+767 T 1096 \u001b[92m☑ 1096\u001b[0m\n",
            "Q 57+720  T 777  \u001b[92m☑ 777 \u001b[0m\n",
            "Q 714+2   T 716  \u001b[92m☑ 716 \u001b[0m\n",
            "Q 78+301  T 379  \u001b[92m☑ 379 \u001b[0m\n",
            "Q 27+45   T 72   \u001b[92m☑ 72  \u001b[0m\n",
            "Q 87+45   T 132  \u001b[92m☑ 132 \u001b[0m\n",
            "Q 68+390  T 458  \u001b[92m☑ 458 \u001b[0m\n",
            "Q 61+897  T 958  \u001b[92m☑ 958 \u001b[0m\n",
            "Q 402+33  T 435  \u001b[92m☑ 435 \u001b[0m\n",
            "Q 869+626 T 1495 \u001b[92m☑ 1495\u001b[0m\n",
            "\n",
            "Iteration 11\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9815 - loss: 0.0842 - val_accuracy: 0.9850 - val_loss: 0.0656\n",
            "Q 837+571 T 1408 \u001b[92m☑ 1408\u001b[0m\n",
            "Q 246+78  T 324  \u001b[92m☑ 324 \u001b[0m\n",
            "Q 648+59  T 707  \u001b[92m☑ 707 \u001b[0m\n",
            "Q 865+77  T 942  \u001b[92m☑ 942 \u001b[0m\n",
            "Q 36+756  T 792  \u001b[92m☑ 792 \u001b[0m\n",
            "Q 368+417 T 785  \u001b[92m☑ 785 \u001b[0m\n",
            "Q 505+60  T 565  \u001b[92m☑ 565 \u001b[0m\n",
            "Q 199+419 T 618  \u001b[91m☒ 617 \u001b[0m\n",
            "Q 310+32  T 342  \u001b[92m☑ 342 \u001b[0m\n",
            "Q 663+79  T 742  \u001b[92m☑ 742 \u001b[0m\n",
            "\n",
            "Iteration 12\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9822 - loss: 0.0739 - val_accuracy: 0.9919 - val_loss: 0.0437\n",
            "Q 21+78   T 99   \u001b[92m☑ 99  \u001b[0m\n",
            "Q 61+55   T 116  \u001b[92m☑ 116 \u001b[0m\n",
            "Q 167+1   T 168  \u001b[92m☑ 168 \u001b[0m\n",
            "Q 548+679 T 1227 \u001b[92m☑ 1227\u001b[0m\n",
            "Q 477+648 T 1125 \u001b[92m☑ 1125\u001b[0m\n",
            "Q 448+1   T 449  \u001b[92m☑ 449 \u001b[0m\n",
            "Q 114+4   T 118  \u001b[92m☑ 118 \u001b[0m\n",
            "Q 182+39  T 221  \u001b[92m☑ 221 \u001b[0m\n",
            "Q 86+492  T 578  \u001b[92m☑ 578 \u001b[0m\n",
            "Q 147+243 T 390  \u001b[92m☑ 390 \u001b[0m\n",
            "\n",
            "Iteration 13\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 0.0537 - val_accuracy: 0.9757 - val_loss: 0.0835\n",
            "Q 773+141 T 914  \u001b[92m☑ 914 \u001b[0m\n",
            "Q 18+529  T 547  \u001b[92m☑ 547 \u001b[0m\n",
            "Q 588+525 T 1113 \u001b[92m☑ 1113\u001b[0m\n",
            "Q 367+18  T 385  \u001b[92m☑ 385 \u001b[0m\n",
            "Q 93+414  T 507  \u001b[92m☑ 507 \u001b[0m\n",
            "Q 62+647  T 709  \u001b[92m☑ 709 \u001b[0m\n",
            "Q 91+511  T 602  \u001b[92m☑ 602 \u001b[0m\n",
            "Q 196+376 T 572  \u001b[92m☑ 572 \u001b[0m\n",
            "Q 901+68  T 969  \u001b[92m☑ 969 \u001b[0m\n",
            "Q 335+72  T 407  \u001b[92m☑ 407 \u001b[0m\n",
            "\n",
            "Iteration 14\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9898 - loss: 0.0442 - val_accuracy: 0.9908 - val_loss: 0.0368\n",
            "Q 957+676 T 1633 \u001b[92m☑ 1633\u001b[0m\n",
            "Q 171+907 T 1078 \u001b[92m☑ 1078\u001b[0m\n",
            "Q 970+37  T 1007 \u001b[92m☑ 1007\u001b[0m\n",
            "Q 58+694  T 752  \u001b[92m☑ 752 \u001b[0m\n",
            "Q 468+735 T 1203 \u001b[92m☑ 1203\u001b[0m\n",
            "Q 214+134 T 348  \u001b[92m☑ 348 \u001b[0m\n",
            "Q 100+9   T 109  \u001b[92m☑ 109 \u001b[0m\n",
            "Q 975+521 T 1496 \u001b[92m☑ 1496\u001b[0m\n",
            "Q 855+937 T 1792 \u001b[92m☑ 1792\u001b[0m\n",
            "Q 774+894 T 1668 \u001b[92m☑ 1668\u001b[0m\n",
            "\n",
            "Iteration 15\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9946 - loss: 0.0271 - val_accuracy: 0.9955 - val_loss: 0.0226\n",
            "Q 744+79  T 823  \u001b[92m☑ 823 \u001b[0m\n",
            "Q 506+11  T 517  \u001b[92m☑ 517 \u001b[0m\n",
            "Q 736+14  T 750  \u001b[92m☑ 750 \u001b[0m\n",
            "Q 7+621   T 628  \u001b[92m☑ 628 \u001b[0m\n",
            "Q 23+674  T 697  \u001b[92m☑ 697 \u001b[0m\n",
            "Q 990+347 T 1337 \u001b[92m☑ 1337\u001b[0m\n",
            "Q 546+981 T 1527 \u001b[92m☑ 1527\u001b[0m\n",
            "Q 364+233 T 597  \u001b[92m☑ 597 \u001b[0m\n",
            "Q 687+84  T 771  \u001b[92m☑ 771 \u001b[0m\n",
            "Q 20+871  T 891  \u001b[92m☑ 891 \u001b[0m\n",
            "\n",
            "Iteration 16\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9949 - loss: 0.0251 - val_accuracy: 0.9953 - val_loss: 0.0237\n",
            "Q 217+343 T 560  \u001b[92m☑ 560 \u001b[0m\n",
            "Q 88+977  T 1065 \u001b[92m☑ 1065\u001b[0m\n",
            "Q 64+221  T 285  \u001b[92m☑ 285 \u001b[0m\n",
            "Q 756+50  T 806  \u001b[92m☑ 806 \u001b[0m\n",
            "Q 72+129  T 201  \u001b[92m☑ 201 \u001b[0m\n",
            "Q 777+50  T 827  \u001b[92m☑ 827 \u001b[0m\n",
            "Q 735+79  T 814  \u001b[92m☑ 814 \u001b[0m\n",
            "Q 30+287  T 317  \u001b[92m☑ 317 \u001b[0m\n",
            "Q 371+622 T 993  \u001b[92m☑ 993 \u001b[0m\n",
            "Q 716+56  T 772  \u001b[92m☑ 772 \u001b[0m\n",
            "\n",
            "Iteration 17\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9909 - loss: 0.0353 - val_accuracy: 0.9655 - val_loss: 0.1093\n",
            "Q 493+824 T 1317 \u001b[92m☑ 1317\u001b[0m\n",
            "Q 733+10  T 743  \u001b[92m☑ 743 \u001b[0m\n",
            "Q 815+76  T 891  \u001b[92m☑ 891 \u001b[0m\n",
            "Q 69+723  T 792  \u001b[92m☑ 792 \u001b[0m\n",
            "Q 487+371 T 858  \u001b[92m☑ 858 \u001b[0m\n",
            "Q 815+407 T 1222 \u001b[92m☑ 1222\u001b[0m\n",
            "Q 0+749   T 749  \u001b[92m☑ 749 \u001b[0m\n",
            "Q 678+810 T 1488 \u001b[91m☒ 1388\u001b[0m\n",
            "Q 9+912   T 921  \u001b[92m☑ 921 \u001b[0m\n",
            "Q 31+402  T 433  \u001b[91m☒ 432 \u001b[0m\n",
            "\n",
            "Iteration 18\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0410 - val_accuracy: 0.9307 - val_loss: 0.2332\n",
            "Q 24+183  T 207  \u001b[91m☒ 206 \u001b[0m\n",
            "Q 1+785   T 786  \u001b[91m☒ 785 \u001b[0m\n",
            "Q 9+971   T 980  \u001b[91m☒ 970 \u001b[0m\n",
            "Q 273+44  T 317  \u001b[92m☑ 317 \u001b[0m\n",
            "Q 267+871 T 1138 \u001b[92m☑ 1138\u001b[0m\n",
            "Q 47+960  T 1007 \u001b[92m☑ 1007\u001b[0m\n",
            "Q 532+464 T 996  \u001b[92m☑ 996 \u001b[0m\n",
            "Q 99+639  T 738  \u001b[92m☑ 738 \u001b[0m\n",
            "Q 64+123  T 187  \u001b[91m☒ 186 \u001b[0m\n",
            "Q 779+14  T 793  \u001b[92m☑ 793 \u001b[0m\n",
            "\n",
            "Iteration 19\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9791 - loss: 0.0670 - val_accuracy: 0.9987 - val_loss: 0.0092\n",
            "Q 296+9   T 305  \u001b[92m☑ 305 \u001b[0m\n",
            "Q 13+94   T 107  \u001b[92m☑ 107 \u001b[0m\n",
            "Q 344+53  T 397  \u001b[92m☑ 397 \u001b[0m\n",
            "Q 99+349  T 448  \u001b[92m☑ 448 \u001b[0m\n",
            "Q 250+53  T 303  \u001b[92m☑ 303 \u001b[0m\n",
            "Q 597+28  T 625  \u001b[92m☑ 625 \u001b[0m\n",
            "Q 88+378  T 466  \u001b[92m☑ 466 \u001b[0m\n",
            "Q 36+171  T 207  \u001b[92m☑ 207 \u001b[0m\n",
            "Q 357+798 T 1155 \u001b[92m☑ 1155\u001b[0m\n",
            "Q 563+82  T 645  \u001b[92m☑ 645 \u001b[0m\n",
            "\n",
            "Iteration 20\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9911 - loss: 0.0311 - val_accuracy: 0.9979 - val_loss: 0.0101\n",
            "Q 9+540   T 549  \u001b[91m☒ 559 \u001b[0m\n",
            "Q 229+881 T 1110 \u001b[92m☑ 1110\u001b[0m\n",
            "Q 759+397 T 1156 \u001b[92m☑ 1156\u001b[0m\n",
            "Q 976+32  T 1008 \u001b[92m☑ 1008\u001b[0m\n",
            "Q 743+35  T 778  \u001b[92m☑ 778 \u001b[0m\n",
            "Q 939+199 T 1138 \u001b[92m☑ 1138\u001b[0m\n",
            "Q 376+361 T 737  \u001b[92m☑ 737 \u001b[0m\n",
            "Q 81+942  T 1023 \u001b[92m☑ 1023\u001b[0m\n",
            "Q 18+689  T 707  \u001b[92m☑ 707 \u001b[0m\n",
            "Q 928+753 T 1681 \u001b[92m☑ 1681\u001b[0m\n",
            "\n",
            "Iteration 21\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9947 - loss: 0.0207 - val_accuracy: 0.9911 - val_loss: 0.0316\n",
            "Q 638+306 T 944  \u001b[92m☑ 944 \u001b[0m\n",
            "Q 109+78  T 187  \u001b[92m☑ 187 \u001b[0m\n",
            "Q 32+290  T 322  \u001b[92m☑ 322 \u001b[0m\n",
            "Q 33+88   T 121  \u001b[92m☑ 121 \u001b[0m\n",
            "Q 663+17  T 680  \u001b[92m☑ 680 \u001b[0m\n",
            "Q 129+61  T 190  \u001b[92m☑ 190 \u001b[0m\n",
            "Q 3+482   T 485  \u001b[92m☑ 485 \u001b[0m\n",
            "Q 53+732  T 785  \u001b[92m☑ 785 \u001b[0m\n",
            "Q 369+97  T 466  \u001b[92m☑ 466 \u001b[0m\n",
            "Q 541+92  T 633  \u001b[92m☑ 633 \u001b[0m\n",
            "\n",
            "Iteration 22\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9890 - loss: 0.0354 - val_accuracy: 0.9973 - val_loss: 0.0116\n",
            "Q 2+196   T 198  \u001b[92m☑ 198 \u001b[0m\n",
            "Q 388+346 T 734  \u001b[92m☑ 734 \u001b[0m\n",
            "Q 470+83  T 553  \u001b[92m☑ 553 \u001b[0m\n",
            "Q 344+25  T 369  \u001b[92m☑ 369 \u001b[0m\n",
            "Q 3+609   T 612  \u001b[92m☑ 612 \u001b[0m\n",
            "Q 463+23  T 486  \u001b[92m☑ 486 \u001b[0m\n",
            "Q 0+707   T 707  \u001b[92m☑ 707 \u001b[0m\n",
            "Q 86+551  T 637  \u001b[92m☑ 637 \u001b[0m\n",
            "Q 933+78  T 1011 \u001b[92m☑ 1011\u001b[0m\n",
            "Q 237+176 T 413  \u001b[92m☑ 413 \u001b[0m\n",
            "\n",
            "Iteration 23\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9891 - loss: 0.0385 - val_accuracy: 0.9947 - val_loss: 0.0182\n",
            "Q 540+79  T 619  \u001b[92m☑ 619 \u001b[0m\n",
            "Q 87+345  T 432  \u001b[92m☑ 432 \u001b[0m\n",
            "Q 172+29  T 201  \u001b[92m☑ 201 \u001b[0m\n",
            "Q 44+755  T 799  \u001b[92m☑ 799 \u001b[0m\n",
            "Q 128+193 T 321  \u001b[92m☑ 321 \u001b[0m\n",
            "Q 0+91    T 91   \u001b[92m☑ 91  \u001b[0m\n",
            "Q 341+575 T 916  \u001b[92m☑ 916 \u001b[0m\n",
            "Q 1+821   T 822  \u001b[92m☑ 822 \u001b[0m\n",
            "Q 456+89  T 545  \u001b[92m☑ 545 \u001b[0m\n",
            "Q 903+96  T 999  \u001b[92m☑ 999 \u001b[0m\n",
            "\n",
            "Iteration 24\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9987 - loss: 0.0065 - val_accuracy: 0.9691 - val_loss: 0.0922\n",
            "Q 256+787 T 1043 \u001b[92m☑ 1043\u001b[0m\n",
            "Q 4+816   T 820  \u001b[92m☑ 820 \u001b[0m\n",
            "Q 985+81  T 1066 \u001b[92m☑ 1066\u001b[0m\n",
            "Q 996+654 T 1650 \u001b[91m☒ 1540\u001b[0m\n",
            "Q 252+600 T 852  \u001b[91m☒ 752 \u001b[0m\n",
            "Q 71+51   T 122  \u001b[92m☑ 122 \u001b[0m\n",
            "Q 485+71  T 556  \u001b[92m☑ 556 \u001b[0m\n",
            "Q 906+769 T 1675 \u001b[92m☑ 1675\u001b[0m\n",
            "Q 9+950   T 959  \u001b[92m☑ 959 \u001b[0m\n",
            "Q 20+382  T 402  \u001b[92m☑ 402 \u001b[0m\n",
            "\n",
            "Iteration 25\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9883 - loss: 0.0404 - val_accuracy: 0.9992 - val_loss: 0.0053\n",
            "Q 912+89  T 1001 \u001b[92m☑ 1001\u001b[0m\n",
            "Q 340+79  T 419  \u001b[92m☑ 419 \u001b[0m\n",
            "Q 364+54  T 418  \u001b[92m☑ 418 \u001b[0m\n",
            "Q 420+478 T 898  \u001b[92m☑ 898 \u001b[0m\n",
            "Q 217+200 T 417  \u001b[92m☑ 417 \u001b[0m\n",
            "Q 975+717 T 1692 \u001b[92m☑ 1692\u001b[0m\n",
            "Q 432+71  T 503  \u001b[92m☑ 503 \u001b[0m\n",
            "Q 830+5   T 835  \u001b[92m☑ 835 \u001b[0m\n",
            "Q 206+65  T 271  \u001b[92m☑ 271 \u001b[0m\n",
            "Q 378+52  T 430  \u001b[92m☑ 430 \u001b[0m\n",
            "\n",
            "Iteration 26\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9912 - loss: 0.0293 - val_accuracy: 0.9984 - val_loss: 0.0074\n",
            "Q 90+881  T 971  \u001b[92m☑ 971 \u001b[0m\n",
            "Q 1+192   T 193  \u001b[92m☑ 193 \u001b[0m\n",
            "Q 52+651  T 703  \u001b[92m☑ 703 \u001b[0m\n",
            "Q 25+848  T 873  \u001b[92m☑ 873 \u001b[0m\n",
            "Q 3+273   T 276  \u001b[92m☑ 276 \u001b[0m\n",
            "Q 155+373 T 528  \u001b[92m☑ 528 \u001b[0m\n",
            "Q 60+220  T 280  \u001b[92m☑ 280 \u001b[0m\n",
            "Q 7+862   T 869  \u001b[92m☑ 869 \u001b[0m\n",
            "Q 181+141 T 322  \u001b[92m☑ 322 \u001b[0m\n",
            "Q 7+671   T 678  \u001b[92m☑ 678 \u001b[0m\n",
            "\n",
            "Iteration 27\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0150 - val_accuracy: 0.9961 - val_loss: 0.0153\n",
            "Q 30+665  T 695  \u001b[92m☑ 695 \u001b[0m\n",
            "Q 477+58  T 535  \u001b[92m☑ 535 \u001b[0m\n",
            "Q 72+438  T 510  \u001b[92m☑ 510 \u001b[0m\n",
            "Q 34+402  T 436  \u001b[92m☑ 436 \u001b[0m\n",
            "Q 25+651  T 676  \u001b[92m☑ 676 \u001b[0m\n",
            "Q 622+25  T 647  \u001b[92m☑ 647 \u001b[0m\n",
            "Q 682+183 T 865  \u001b[92m☑ 865 \u001b[0m\n",
            "Q 648+851 T 1499 \u001b[92m☑ 1499\u001b[0m\n",
            "Q 143+58  T 201  \u001b[92m☑ 201 \u001b[0m\n",
            "Q 0+152   T 152  \u001b[92m☑ 152 \u001b[0m\n",
            "\n",
            "Iteration 28\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9990 - loss: 0.0064 - val_accuracy: 0.9724 - val_loss: 0.0903\n",
            "Q 615+865 T 1480 \u001b[92m☑ 1480\u001b[0m\n",
            "Q 649+87  T 736  \u001b[92m☑ 736 \u001b[0m\n",
            "Q 565+62  T 627  \u001b[92m☑ 627 \u001b[0m\n",
            "Q 450+870 T 1320 \u001b[92m☑ 1320\u001b[0m\n",
            "Q 849+99  T 948  \u001b[92m☑ 948 \u001b[0m\n",
            "Q 30+842  T 872  \u001b[92m☑ 872 \u001b[0m\n",
            "Q 1+471   T 472  \u001b[92m☑ 472 \u001b[0m\n",
            "Q 570+69  T 639  \u001b[92m☑ 639 \u001b[0m\n",
            "Q 132+8   T 140  \u001b[92m☑ 140 \u001b[0m\n",
            "Q 30+188  T 218  \u001b[92m☑ 218 \u001b[0m\n",
            "\n",
            "Iteration 29\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0132 - val_accuracy: 0.9995 - val_loss: 0.0036\n",
            "Q 77+902  T 979  \u001b[92m☑ 979 \u001b[0m\n",
            "Q 123+517 T 640  \u001b[92m☑ 640 \u001b[0m\n",
            "Q 934+47  T 981  \u001b[92m☑ 981 \u001b[0m\n",
            "Q 604+11  T 615  \u001b[92m☑ 615 \u001b[0m\n",
            "Q 348+83  T 431  \u001b[92m☑ 431 \u001b[0m\n",
            "Q 570+77  T 647  \u001b[92m☑ 647 \u001b[0m\n",
            "Q 889+636 T 1525 \u001b[92m☑ 1525\u001b[0m\n",
            "Q 48+23   T 71   \u001b[92m☑ 71  \u001b[0m\n",
            "Q 827+331 T 1158 \u001b[92m☑ 1158\u001b[0m\n",
            "Q 840+499 T 1339 \u001b[92m☑ 1339\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Training parameters.\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "# Formatting characters for results display.\n",
        "green_color = \"\\033[92m\"\n",
        "red_color = \"\\033[91m\"\n",
        "end_char = \"\\033[0m\"\n",
        "\n",
        "# Train the model each generation and show predictions against the validation\n",
        "# dataset.\n",
        "for epoch in range(1, epochs):\n",
        "    print()\n",
        "    print(\"Iteration\", epoch)\n",
        "    model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=1,\n",
        "        validation_data=(x_val, y_val),\n",
        "    )\n",
        "    # Select 10 samples from the validation set at random so we can visualize\n",
        "    # errors.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = np.argmax(model.predict(rowx, verbose=0), axis=-1)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
        "        print(\"T\", correct, end=\" \")\n",
        "        if correct == guess:\n",
        "            print(f\"{green_color}☑ {guess}{end_char}\")\n",
        "        else:\n",
        "            print(f\"{red_color}☒ {guess}{end_char}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P3LID9IynlZ"
      },
      "source": [
        "You'll get to 99+% validation accuracy after ~30 epochs."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}